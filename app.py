import streamlit as st
import google.generative_ai as genai
import tempfile
import os
import cv2
from PIL import Image
import concurrent.futures

# --- é¡µé¢é…ç½® ---
st.set_page_config(page_title="AI æé€Ÿåˆ†é•œåŠ©æ‰‹", page_icon="ğŸ¬", layout="wide")

st.title("ğŸ¬ AI è§†é¢‘åˆ†é•œåˆ†æ (å…­æ ¼æé€Ÿç‰ˆ)")
st.markdown("ä¸Šä¼ è§†é¢‘ï¼Œè‡ªåŠ¨æˆªå– 6 å¼ å…³é”®å¸§ï¼Œå¹¶å¹¶å‘è°ƒç”¨ AI è¿›è¡Œè§£è¯´ã€‚")

# --- ä¾§è¾¹æ  ---
with st.sidebar:
    st.header("ğŸ”‘ ç¬¬ä¸€æ­¥")
    api_key = st.text_input("è¾“å…¥ Google API Key", type="password", help="ç²˜è´´ä»¥ AIza å¼€å¤´çš„å¯†é’¥")
    st.markdown("---")
    if not api_key:
        st.warning("ğŸ”´ ç­‰å¾…è¾“å…¥ Key")
    else:
        st.success("ğŸŸ¢ Key å·²å°±ç»ª")
    st.markdown("### ğŸ“ ä½¿ç”¨è¯´æ˜")
    st.markdown("1. ç²˜è´´ Key\n2. ä¸Šä¼ è§†é¢‘\n3. ç‚¹å‡»å¼€å§‹")

# --- æ ¸å¿ƒåŠŸèƒ½ 1: æˆªå–å›¾ç‰‡ ---
def extract_6_keyframes(video_path):
    cap = cv2.VideoCapture(video_path)
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    if total_frames == 0:
        cap.release()
        return []

    # æŒ‰ 7 ç­‰åˆ†å– 6 å¸§
    frame_indices = [int(total_frames * (i + 1) / 7) for i in range(6)]
    images = []

    for idx in frame_indices:
        cap.set(cv2.CAP_PROP_POS_FRAMES, idx)
        ret, frame = cap.read()
        if ret and frame is not None:
            rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            images.append(Image.fromarray(rgb_frame))
        else:
            # å ä½ç°å›¾ï¼Œé¿å…æŠ¥é”™
            images.append(Image.new("RGB", (200, 200), color="gray"))

    cap.release()
    return images

# --- æ ¸å¿ƒåŠŸèƒ½ 2: å¹¶å‘ AI åˆ†æ ---
def analyze_single_image(img, model):
    try:
        prompt = "è¯·ç”¨ä¸€å¥ä¸­æ–‡ç®€è¿°ç”»é¢å†…å®¹ï¼ˆä¾‹å¦‚äººç‰©åŠ¨ä½œï¼‰å’Œæ™¯åˆ«ï¼ˆç‰¹å†™/å…¨æ™¯ï¼‰ã€‚"
        # Gemini æ”¯æŒç›´æ¥ä¼  PIL.Image
        response = model.generate_content([prompt, img])
        return response.text.strip()
    except Exception as e:
        return f"åˆ†æå¤±è´¥ï¼š{e}"

def analyze_images_concurrently(images, model):
    descriptions = [""] * len(images)
    status = st.empty()
    status.info("âš¡ï¸ æ­£åœ¨å¯åŠ¨å¤šçº¿ç¨‹ AI åˆ†æï¼Œè¯·ç¨å€™...")

    with concurrent.futures.ThreadPoolExecutor(max_workers=len(images)) as executor:
        future_to_index = {
            executor.submit(analyze_single_image, img, model): i
            for i, img in enumerate(images)
        }
        for future in concurrent.futures.as_completed(future_to_index):
            i = future_to_index[future]
            try:
                descriptions[i] = future.result()
            except Exception as e:
                descriptions[i] = f"åˆ†æå¤±è´¥ï¼š{e}"

    status.empty()
    return descriptions

# --- åˆå§‹åŒ–æ¨¡å‹ ---
model = None
if api_key:
    try:
        genai.configure(api_key=api_key)
        model = genai.GenerativeModel("gemini-1.5-flash")
    except Exception as e:
        model = None
        st.error(f"Key æ ¼å¼ä¸å¯¹æˆ–åˆå§‹åŒ–å¤±è´¥ï¼š{e}")

# --- ä¸»ç¨‹åºé€»è¾‘ ---
uploaded_file = st.file_uploader(
    "ğŸ“‚ ç¬¬äºŒæ­¥ï¼šæ‹–å…¥è§†é¢‘ (å»ºè®® < 50MB)", type=["mp4", "mov", "m4v", "avi"]
)

if uploaded_file and st.button("ğŸš€ å¼€å§‹æé€Ÿåˆ†æ"):
    if not api_key or model is None:
        st.error("è¯·å…ˆè¾“å…¥æœ‰æ•ˆçš„ Google API Key")
    else:
        # å…ˆæŠŠä¸Šä¼ çš„è§†é¢‘ä¿å­˜åˆ°ä¸´æ—¶æ–‡ä»¶
        suffix = os.path.splitext(uploaded_file.name)[1] or ".mp4"
        with tempfile.NamedTemporaryFile(delete=False, suffix=suffix) as tmp:
            tmp.write(uploaded_file.read())
            tmp_path = tmp.name

        st.info("â³ æ­£åœ¨ä»è§†é¢‘ä¸­æå– 6 å¼ å…³é”®å¸§...")
        images = extract_6_keyframes(tmp_path)

        # ç”¨å®Œå°±åˆ æ‰ä¸´æ—¶æ–‡ä»¶
        try:
            os.remove(tmp_path)
        except OSError:
            pass

        if not images:
            st.error("âŒ æ— æ³•ä»è§†é¢‘ä¸­è¯»å–å¸§ï¼Œè¯·æ£€æŸ¥è§†é¢‘æ–‡ä»¶æ˜¯å¦æŸåã€‚")
        else:
            st.success("âœ… å·²æˆåŠŸæå– 6 å¼ å…³é”®å¸§ï¼")

            # å…ˆå±•ç¤ºå›¾ç‰‡
            st.subheader("ğŸ–¼ æˆªå–ç»“æœé¢„è§ˆ")
            cols = st.columns(3)
            for i, img in enumerate(images):
                with cols[i % 3]:
                    st.image(img, caption=f"ç¬¬ {i + 1} å¼ å…³é”®å¸§", use_column_width=True)

            # è°ƒç”¨ AI åˆ†æ
            st.subheader("ğŸ§  AI åˆ†é•œè§£è¯´")
            with st.spinner("æ­£åœ¨è°ƒç”¨ Gemini è¿›è¡Œå›¾åƒç†è§£..."):
                descriptions = analyze_images_concurrently(images, model)

            # å›¾ + æ–‡ å¯¹åº”å±•ç¤º
            for i, (img, desc) in enumerate(zip(images, descriptions)):
                st.markdown(f"**ç¬¬ {i + 1} å¼ ï¼š** {desc}")
