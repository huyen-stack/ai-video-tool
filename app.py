import streamlit as st
import google.generativeai as genai
import tempfile
import os
import cv2
import numpy as np
from PIL import Image, ImageDraw
import concurrent.futures
import json
from datetime import datetime
import yt_dlp  # æŠ–éŸ³/Bç«™/TikTok/YouTube ä¸‹è½½
from typing import Optional, Tuple, List, Dict, Any

# ========================
# å…¨å±€é…ç½®
# ========================

GEMINI_MODEL_NAME = "gemini-flash-latest"  # å¯æ¢æˆ gemini-2.5-flash-lite ç­‰

# å…è´¹ç‰ˆå…¸å‹é€Ÿç‡ï¼šæ¯åˆ†é’Ÿ 10 æ¬¡ generateContent
FREE_TIER_RPM_LIMIT = 10

DISPLAY_IMAGE_WIDTH = 320
PALETTE_WIDTH = 320
PALETTE_HEIGHT = 26

# åˆå§‹åŒ–ä¼šè¯çŠ¶æ€ï¼šAPI Key + å†å²è®°å½•
if "api_key" not in st.session_state:
    st.session_state["api_key"] = ""
if "analysis_history" not in st.session_state:
    # æ¯æ¡å…ƒç´ ç»“æ„ï¼š
    # {
    #   "id": "run_1",
    #   "created_at": "...",
    #   "meta": {...},
    #   "data": {... å®Œæ•´ export_data ...}
    # }
    st.session_state["analysis_history"] = []


# ========================
# é¡µé¢ / å…¨å±€æ ·å¼
# ========================

st.set_page_config(
    page_title="AI è‡ªåŠ¨å…³é”®å¸§åˆ†é•œ & è§†é¢‘æç¤ºè¯åŠ©æ‰‹",
    page_icon="ğŸ¬",
    layout="wide",
)

st.markdown(
    """
    <style>
    .main {
        background-color: #0f172a;
        color: #e5e7eb;
    }
    .stMarkdown, .stText {
        color: #e5e7eb;
    }
    .stCode {
        font-size: 0.85rem !important;
    }
    </style>
    """,
    unsafe_allow_html=True,
)

st.markdown(
    """
    <div style="
        padding: 18px 24px;
        border-radius: 18px;
        margin-bottom: 16px;
        background: radial-gradient(circle at top left, #38bdf8 0, #0f172a 45%, #020617 100%);
        border: 1px solid rgba(148, 163, 184, 0.35);
    ">
      <h1 style="margin: 0 0 8px 0; color: #e5e7eb; font-size: 1.6rem;">
        ğŸ¬ AI è‡ªåŠ¨å…³é”®å¸§åˆ†é•œåŠ©æ‰‹ Pro Â· SORA/VEO è§†é¢‘æç¤ºè¯ + æ—¶é—´åŒºé—´ + å†å²è®°å½•
      </h1>
      <p style="margin: 0; color: #cbd5f5; font-size: 0.96rem;">
        ä¸Šä¼ è§†é¢‘æˆ–è¾“å…¥æŠ–éŸ³/Bç«™/TikTok/YouTube é“¾æ¥ï¼Œè®¾ç½®åˆ†ææ—¶é—´åŒºé—´ï¼Œè‡ªåŠ¨æŠ½å–å…³é”®å¸§ï¼Œç”Ÿæˆ
        <b>ç»“æ„åŒ– JSON + Midjourney æç¤ºè¯ + SORA/VEO è‹±æ–‡è§†é¢‘æç¤ºè¯ + åˆ†é•œè§£è¯» + å‰§æƒ…å¤§çº² + 10 ç§’å¹¿å‘Šæ—ç™½ + æ—¶é—´è½´åˆ†é•œè„šæœ¬</b>ï¼Œ
        å¹¶åœ¨å½“å‰ä¼šè¯ä¸­ä¿å­˜å¤šæ¡åˆ†æè®°å½•ï¼Œæ–¹ä¾¿å¯¹æ¯”ä¸ä¸‹è½½ã€‚
      </p>
    </div>
    """,
    unsafe_allow_html=True,
)


# ========================
# æŠ½å…³é”®å¸§ï¼ˆæ”¯æŒæ—¶é—´åŒºé—´ï¼‰
# ========================

def extract_keyframes_dynamic(
    video_path: str,
    min_frames: int = 6,
    max_frames: int = 30,
    base_fps: float = 0.8,
    start_sec: Optional[float] = None,
    end_sec: Optional[float] = None,
) -> Tuple[List[Image.Image], float, Tuple[float, float]]:
    """
    æ ¹æ®è§†é¢‘æ—¶é•¿è‡ªåŠ¨æŠ½å–å…³é”®å¸§ï¼Œä»…åœ¨ [start_sec, end_sec] èŒƒå›´å†…ã€‚
    è¿”å›ï¼š
      images: æŠ½åˆ°çš„ PIL.Image åˆ—è¡¨
      duration: æ•´æ¡è§†é¢‘æ€»æ—¶é•¿ï¼ˆç§’ï¼‰
      used_range: (start_used, end_used) å®é™…ç”Ÿæ•ˆçš„åˆ†ææ—¶é—´èŒƒå›´ï¼ˆç§’ï¼‰
    """
    cap = cv2.VideoCapture(video_path)
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    fps = cap.get(cv2.CAP_PROP_FPS)
    if fps is None or fps <= 1e-2:
        fps = 25.0

    if total_frames <= 0:
        cap.release()
        return [], 0.0, (0.0, 0.0)

    duration = total_frames / fps  # æ•´æ¡è§†é¢‘æ—¶é•¿

    # è§„èŒƒåŒ–æ—¶é—´èŒƒå›´
    if start_sec is None or start_sec < 0:
        start_sec = 0.0
    if end_sec is None or end_sec <= start_sec or end_sec > duration:
        end_sec = duration

    start_frame = int(start_sec * fps)
    end_frame_excl = min(total_frames, int(end_sec * fps))
    segment_frames = end_frame_excl - start_frame

    # å¦‚æœåŒºé—´éæ³•ï¼Œé€€å›æ•´æ®µ
    if segment_frames <= 0:
        start_sec = 0.0
        end_sec = duration
        start_frame = 0
        end_frame_excl = total_frames
        segment_frames = total_frames

    segment_duration = segment_frames / fps

    ideal_n = int(segment_duration * base_fps)
    target_n = max(min_frames, ideal_n)
    target_n = min(target_n, max_frames, segment_frames)

    if target_n <= 0:
        cap.release()
        return [], duration, (start_sec, end_sec)

    step = segment_frames / float(target_n)
    frame_indices = [start_frame + int(i * step) for i in range(target_n)]

    images: List[Image.Image] = []
    for idx in frame_indices:
        cap.set(cv2.CAP_PROP_POS_FRAMES, idx)
        ret, frame = cap.read()
        if ret and frame is not None:
            rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            images.append(Image.fromarray(rgb_frame))
        else:
            images.append(Image.new("RGB", (200, 200), color="gray"))

    cap.release()
    return images, duration, (start_sec, end_sec)


# ========================
# ä»é“¾æ¥ä¸‹è½½è§†é¢‘
# ========================

def download_video_from_url(url: str) -> str:
    """ä½¿ç”¨ yt-dlp ä»ç»™å®š URL ä¸‹è½½è§†é¢‘åˆ°ä¸´æ—¶æ–‡ä»¶ï¼Œè¿”å›è·¯å¾„ã€‚"""
    if not url:
        raise ValueError("è§†é¢‘é“¾æ¥ä¸ºç©º")

    tmp = tempfile.NamedTemporaryFile(delete=False, suffix=".mp4")
    tmp_path = tmp.name
    tmp.close()

    ydl_opts = {
        "format": "mp4/bestvideo+bestaudio/best",
        "outtmpl": tmp_path,
        "merge_output_format": "mp4",
        "quiet": True,
        "no_warnings": True,
    }

    with yt_dlp.YoutubeDL(ydl_opts) as ydl:
        ydl.download([url])

    return tmp_path


# ========================
# ä¸»è‰²è°ƒè‰²å¡ç›¸å…³
# ========================

def get_color_palette(pil_img: Image.Image, num_colors: int = 5):
    img_small = pil_img.resize((120, 120))
    arr = np.array(img_small)
    data = arr.reshape((-1, 3)).astype(np.float32)

    criteria = (
        cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER,
        20,
        1.0,
    )
    flags = cv2.KMEANS_RANDOM_CENTERS

    _, labels, centers = cv2.kmeans(
        data,
        num_colors,
        None,
        criteria,
        10,
        flags,
    )
    centers = centers.astype(int)
    colors = [tuple(map(int, c)) for c in centers]
    return colors


def make_palette_image(colors, width: int = PALETTE_WIDTH, height: int = PALETTE_HEIGHT):
    if not colors:
        return Image.new("RGB", (width, height), color="gray")

    bar = Image.new("RGB", (width, height))
    draw = ImageDraw.Draw(bar)
    n = len(colors)
    band_width = max(width // n, 1)

    for i, color in enumerate(colors):
        x0 = i * band_width
        x1 = width if i == n - 1 else (i + 1) * band_width
        draw.rectangle([x0, 0, x1, height], fill=color)

    return bar


def rgb_to_hex(rgb_tuple):
    r, g, b = rgb_tuple
    return "#{:02X}{:02X}{:02X}".format(r, g, b)


# ========================
# è§£æ Gemini è¿”å›
# ========================

def _extract_text_from_response(resp) -> str:
    text = getattr(resp, "text", None)
    if text and isinstance(text, str) and text.strip():
        return text.strip()

    try:
        texts = []
        for cand in getattr(resp, "candidates", []) or []:
            content = getattr(cand, "content", None)
            if not content:
                continue
            for part in getattr(content, "parts", []) or []:
                part_text = getattr(part, "text", None)
                if part_text:
                    texts.append(part_text)
        if texts:
            return " ".join(texts).strip()
    except Exception:
        pass

    try:
        return str(resp)
    except Exception:
        return ""


# ========================
# å•å¸§åˆ†æï¼šç»“æ„åŒ– JSON + MJ æç¤ºè¯ + è§†é¢‘æç¤ºè¯
# ========================

def analyze_single_image(img: Image.Image, model, index: int) -> Dict[str, Any]:
    """
    å¯¹å•å¸§åšå…¨é¢åˆ†æï¼š
    - ä¸­æ–‡åˆ†é•œï¼ˆæ™¯åˆ«/æœºä½/å…‰çº¿/æƒ…ç»ª/æ ‡ç­¾ï¼‰
    - äººç‰©æœé¥°/è¡¨æƒ…/åŠ¨ä½œ/é“å…·
    - åœºæ™¯ç»†èŠ‚ / ç§‘æŠ€é“å…· / åŠ¨ä½œè¶‹åŠ¿
    - ç‰©ç† & ç¯å¢ƒç»†èŠ‚ï¼ˆé£é›¨é›ªã€å¤´å‘è¡£ç‰©ååº”ã€å—åŠ›å½¢å˜ã€ç»“æ„ç ´åã€ç¢ç‰‡é£æ•£ç­‰ï¼‰
    - Midjourney æç¤ºè¯
    - SORA/VEO ç”¨è‹±æ–‡è§†é¢‘æç¤ºè¯ video_prompt_en
    """
    try:
        prompt = f"""
ä½ ç°åœ¨æ˜¯ç”µå½±å¯¼æ¼” + æ‘„å½±æŒ‡å¯¼ + æœåŒ–é“æ€»ç›‘ + æç¤ºè¯å·¥ç¨‹å¸ˆã€‚
è¯·ä»”ç»†åˆ†æç»™ä½ çš„è¿™ä¸€å¸§ç”»é¢ï¼Œå¹¶è¾“å‡ºä¸€ä¸ª JSON å¯¹è±¡ï¼Œç”¨äºï¼š
1ï¼‰äººç±»å¯¼æ¼”é˜…è¯»åˆ†é•œ
2ï¼‰Midjourney ç”Ÿæˆåˆ†é•œå›¾
3ï¼‰SORA/VEO ç­‰è§†é¢‘æ¨¡å‹ç”Ÿæˆå¯¹åº”é•œå¤´

å¿…é¡»ä½¿ç”¨ä¸‹é¢è¿™äº› keyï¼ˆè‹±æ–‡ï¼‰ï¼Œvalue å¤§éƒ¨åˆ†ä¸ºä¸­æ–‡è¯´æ˜ï¼Œè‹±æ–‡æç¤ºè¯å­—æ®µä¸ºè‹±æ–‡ï¼š

{{
  "index": æ•´æ•°ï¼Œå½“å‰å¸§åºå·ï¼Œå›ºå®šä¸º {index},

  "scene_description_zh": (
    "ç”¨ 1ï½3 å¥å®Œæ•´ä¸­æ–‡ï¼ŒæŠŠå½“å‰ç”»é¢æè¿°å¾—å°½é‡å…·ä½“ï¼Œå¿…é¡»åŒæ—¶åŒ…å«ï¼š"
    "1ï¼‰ä¸»è¦äººç‰©çš„èº«ä»½ + å¤§è‡´å¹´é¾„ + æ€§åˆ« + å¤–è§‚ç‰¹å¾ï¼ˆå°¤å…¶æ˜¯æœè£…é¢œè‰²/æ¬¾å¼ã€æ˜¯å¦æœ‰æŠ«é£ã€å¤´é¥°ç­‰ï¼‰ï¼›"
    "2ï¼‰æ­¤åˆ»æ­£åœ¨åšçš„åŠ¨ä½œä»¥åŠåŠ¨ä½œæ–¹å‘å’Œé€Ÿåº¦æ„Ÿï¼ˆä¾‹å¦‚ï¼šä»ç”»é¢å³ä¸Šé«˜é€Ÿæ»‘å‘å·¦ä¸‹ã€æŠ¬æ‰‹æ¨å¼€é—¨ã€ä½å¤´çœ‹æ‰‹æœºï¼‰ï¼Œ"
    "å¦‚æœç”»é¢æ˜æ˜¾å¤„åœ¨ä¸€ä¸ªæé™åŠ¨ä½œè¿‡ç¨‹ä¹‹ä¸­ï¼ˆä¾‹å¦‚ï¼šæ‘©æ‰˜è½¦åˆšä»å±±å¡é£å‡ºå‡†å¤‡è½åœ¨é£æœºæœºç¿¼ä¸Šï¼Œäººç‰©å³å°†æŠ›å¼ƒè½½å…·è·³åˆ°æœºç¿¼ä¸Šï¼‰ï¼Œ"
    "è¦ç”¨ä¸€å¥å®Œæ•´çš„è¯æŠŠâ€œä»å“ªé‡Œé£æ¥/é£å‘å“ªé‡Œâ€çš„è¿åŠ¨è·¯å¾„è¯´å‡ºæ¥ï¼Œè€Œä¸æ˜¯åªå†™â€œäººç‰©åœ¨ç©ºä¸­â€æˆ–â€œåœ¨é£æœºæ—è¾¹â€ï¼›"
    "3ï¼‰æ‰€åœ¨çš„åœºæ™¯ç±»å‹ä¸ç©ºé—´ç»“æ„ï¼ˆä¾‹å¦‚ï¼šä¸´æµ·å±±è·¯ã€å³¡è°·ã€åŸå¸‚é«˜æ¥¼ä¹‹é—´çš„ç©ºä¸­è½¨é“ï¼‰ï¼Œåˆ†æ¸…å‰æ™¯/ä¸­æ™¯/èƒŒæ™¯é‡Œå„æœ‰ä»€ä¹ˆç‰©ä½“ï¼ˆæ‚¬å´–ã€æµ·é¢ã€æ ‘æœ¨ã€æˆ¿å±‹ã€è½¦æµç­‰ï¼‰ï¼Œä»¥åŠåœ°å½¢ç‰¹å¾ï¼ˆèœ¿èœ’ã€é™¡å¡ã€æ‚¬ç©ºå¹³å°ç­‰ï¼‰ï¼›"
    "4ï¼‰é•œå¤´ç›¸å¯¹äººç‰©çš„ä½ç½®å’Œè§†è§’ï¼ˆä¾‹å¦‚ï¼šç¬¬ä¸€äººç§°è§†è§’ã€ç´§è´´èƒŒåçš„è¿½éšè§†è§’ã€è‚©è†€åè§†è§’ã€ä»ä¾§åæ–¹ç•¥ä»°æ‹ã€ä¿¯è§†ä¿¯å†²ç­‰ï¼‰ï¼Œä»¥åŠé•œå¤´å¤§è‡´æ²¿ç€ä»€ä¹ˆæ–¹å‘è¿åŠ¨ã€‚"
    "ç¦æ­¢åªå†™â€œæŸäººç«™åœ¨æŸå¤„â€æˆ–â€œäººç‰©åœ¨è·¯ä¸Šç§»åŠ¨â€è¿™ç§æ¨¡ç³Šå¥å­ï¼Œå¿…é¡»å†™åˆ°è®©ç¾æœ¯æˆ– 3D åœºæ™¯å¸ˆèƒ½æŒ‰æ–‡å­—æ­åœºæ™¯çš„ç¨‹åº¦ï¼›"
    "å¿½ç•¥ç”»é¢ä¸­çš„ App UI å›¾æ ‡/æ–‡å­—/ç•Œé¢å…ƒç´ ï¼Œä¸è¦æŠŠæŠ–éŸ³/å¿«æ‰‹æŒ‰é’®å†™è¿›æè¿°ã€‚"
  ),

  "tags_zh": ["#çŸ­ä¸­æ–‡æ ‡ç­¾1", "#æ ‡ç­¾2", "..."],

  "camera": {{
    "shot_type_zh": "æ™¯åˆ«ï¼Œä¾‹å¦‚ï¼šè¿œæ™¯ / å…¨æ™¯ / ä¸­æ™¯ / ä¸­è¿‘æ™¯ / è¿‘æ™¯ / ç‰¹å†™",
    "shot_type": "è‹±æ–‡æ™¯åˆ«ï¼Œä¾‹å¦‚ï¼šwide shot, full shot, medium shot, medium close-up, close-up",
    "angle_zh": "æ‹æ‘„è§’åº¦ï¼Œä¾‹å¦‚ï¼šä¿¯æ‹ / ä»°æ‹ / å¹³è§† / ä¸Šå¸è§†è§’ / ä¾§æ‹ç­‰",
    "angle": "è‹±æ–‡è§’åº¦æè¿°ï¼Œä¾‹å¦‚ï¼šeye-level, low angle, high angle, top-down",
    "movement_zh": "è¿é•œæ–¹å¼ï¼Œä¾‹å¦‚ï¼šé™æ­¢é•œå¤´ / ç¼“æ…¢æ¨è¿‘ / æ‰‹æŒè·Ÿæ‹ / æ¨ªç§» / ç”©é•œ ç­‰",
    "movement": "è‹±æ–‡è¿é•œæè¿°ï¼Œä¾‹å¦‚ï¼šslow dolly-in, handheld tracking from left to right",
    "composition_zh": "æ„å›¾æ–¹å¼ï¼Œä¾‹å¦‚ï¼šä¸‰åˆ†æ³•æ„å›¾ / ä¸­å¿ƒæ„å›¾ / å¯¹ç§°æ„å›¾ / å‰æ™¯-ä¸»ä½“-èƒŒæ™¯ ç­‰",
    "composition": "è‹±æ–‡æ„å›¾æè¿°ï¼Œä¾‹å¦‚ï¼šrule-of-thirds, subject on right third, strong foreground elements"
  }},

  "color_and_light_zh": "ç”¨ 1ï½2 å¥ä¸­æ–‡æè¿°ç”»é¢çš„æ•´ä½“è‰²è°ƒå’Œå…‰çº¿ï¼ˆè‰²æ¸©/å¯¹æ¯”/ä¸»å…‰æºæ–¹å‘åŠæ˜¯å¦æœ‰é€†å…‰/è½®å»“å…‰ç­‰ï¼‰",
  "mood_zh": "ç”¨ä¸­æ–‡æ¦‚æ‹¬æƒ…ç»ªæ°›å›´ï¼ˆç´§å¼ /æ¸©æš–/æ¢¦å¹»/å†·å³»/å•†ä¸šæ„Ÿç­‰ï¼‰",

  "characters": [
    {{
      "role_zh": "äººç‰©èº«ä»½ï¼Œä¾‹å¦‚ï¼šå¥³ä¸» / ç”·ä¸» / ç§‘å­¦å®¶ / ä¾¦æ¢ / å¨å¸ˆ",
      "gender_zh": "æ€§åˆ«ï¼Œä¾‹å¦‚ï¼šå¥³æ€§ / ç”·æ€§ / ä¸æ˜æ˜¾",
      "age_look_zh": "å¹´é¾„è§‚æ„Ÿï¼Œä¾‹å¦‚ï¼š20å¤šå² / ä¸­å¹´",
      "body_type_zh": "ä½“å‹ï¼Œä¾‹å¦‚ï¼šåç˜¦ / å¥å£®",
      "clothing_zh": "æœè£…é£æ ¼ä¸é¢œè‰²ï¼Œä¾‹å¦‚ï¼šç™½è‰²ç§‘æŠ€æ„Ÿç´§èº«è¡£ï¼Œå¸¦è“è‰²å‘å…‰çº¹è·¯",
      "hair_zh": "å‘å‹ä¸å‘è‰²ï¼Œä¾‹å¦‚ï¼šçŸ­å‘ï¼Œé»‘è‰²æˆ–é“¶è‰²æŒ‘æŸ“",
      "expression_zh": "é¢éƒ¨è¡¨æƒ…ï¼Œä¾‹å¦‚ï¼šä¸“æ³¨ã€æ„¤æ€’ã€æƒŠè®¶ã€è½»æ¾å¾®ç¬‘",
      "pose_body_zh": "èº«ä½“å§¿æ€ï¼Œä¾‹å¦‚ï¼šå‰å€¾æ“ä½œæ§åˆ¶å° / åŠè¹²å‡†å¤‡èµ·è·³ / èº«ä½“åä»°æ­£åœ¨åˆ¹è½¦",
      "props_zh": "äººç‰©æ‰‹ä¸Šæˆ–èº«ä¸Šæ˜æ˜¾å¯è§çš„é“å…·ï¼Œä¾‹å¦‚ï¼šæ‰‹æªã€å…‰å‰‘ã€å¹³åº•é”…ã€å¹³æ¿ç”µè„‘ã€é£è¡Œæ‰«å¸š"
    }}
  ],

  "character_action_detail_zh": (
    "ä¸“é—¨æè¿°äººç‰©åŠ¨ä½œçš„ç»†èŠ‚ï¼Œç”¨ 1ï½3 å¥å®Œæ•´ä¸­æ–‡ï¼Œä»â€œå¤´éƒ¨â†’ä¸Šè‚¢â†’èº¯å¹²â†’ä¸‹è‚¢â€çš„é¡ºåºå†™ã€‚"
    "å¿…é¡»è¯´æ¸…ï¼š1ï¼‰æ­¤åˆ»èº«ä½“é‡å¿ƒä½ç½®ï¼ˆä¾‹å¦‚ï¼šå‰å€¾ã€åä»°ã€è¹²ä¸‹ã€è…¾ç©ºã€è´´åœ¨æŸç‰©è¡¨é¢ï¼‰ï¼›"
    "2ï¼‰åŒæ‰‹/æ‰‹æŒ‡åœ¨åšä»€ä¹ˆåŠ¨ä½œï¼ˆä¾‹å¦‚ï¼šå³æ‰‹æ­»æ­»æŠ“ä½æœºç¿¼è¾¹ç¼˜ï¼Œå·¦æ‰‹æ’‘ä½æ‘©æ‰˜è½¦è½¦æŠŠï¼Œæ‰‹æŒ‡åƒåŠ›ç»·ç´§ï¼‰ï¼›"
    "3ï¼‰åŒè…¿/è„šçš„å§¿æ€å’ŒæŒ‡å‘ï¼ˆä¾‹å¦‚ï¼šåŒè…¿å¤¹ç´§æ²¹ç®±ï¼Œè„šå°–æœå¤–ä¼¸ç›´ï¼Œå³è„šåˆšç¦»å¼€å±±å¡è¾¹ç¼˜ï¼‰ï¼›"
    "4ï¼‰ä¸é“å…·æˆ–ç¯å¢ƒçš„å…·ä½“æ¥è§¦ç‚¹ï¼ˆä¾‹å¦‚ï¼šè†ç›–æŠµåœ¨æœºç¿¼è¡¨é¢ã€è„šè·Ÿè¸©åœ¨æ æ†ä¸Šï¼‰ã€‚"
    "ç¦æ­¢å†™æˆâ€œäººç‰©å¥”è·‘/è·³è·ƒâ€è¿™ç§ç¬¼ç»Ÿæè¿°ï¼Œå¿…é¡»å†™åˆ°è¯»è€…èƒ½åœ¨è„‘ä¸­çœ‹åˆ°å…·ä½“è‚¢ä½“å§¿æ€ã€‚"
  ),

  "face_expression_detail_zh": (
    "ä¸“é—¨æè¿°é¢éƒ¨è¡¨æƒ…ä¸çœ¼ç¥å˜åŒ–ï¼Œç”¨ 1ï½3 å¥ä¸­æ–‡å†™æ¸…ï¼š"
    "1ï¼‰çœ‰æ¯›ã€çœ¼ç›ã€å˜´è§’ã€ä¸‹é¢Œç­‰è‚Œè‚‰çš„çŠ¶æ€ï¼ˆç´§ç»·/æ”¾æ¾/æŠ½åŠ¨ç­‰ï¼‰ï¼›"
    "2ï¼‰çœ¼ç›çš„ç»†èŠ‚ï¼šçœ¼è‰²ã€ç³å­”å¤§å°ã€æ˜¯å¦å……è¡€/æ³›å…‰ã€æ˜¯å¦æœ‰æ³ªå…‰ï¼›"
    "3ï¼‰å¦‚æœæœ‰é£ã€é›¨ã€æ‹³å¤´æ‰“åœ¨è„¸ä¸Šç­‰å¤–åŠ›ï¼Œè„¸éƒ¨æ˜¯å¦å‡ºç°å½¢å˜ã€æŠ–åŠ¨ã€å›å¼¹ã€‚"
  ),

  "cloth_hair_reaction_zh": (
    "ç”¨ 1ï½3 å¥ä¸­æ–‡å†™æ¸…äººç‰©å¤´å‘å’Œè¡£æœå¯¹é£/åŠ¨ä½œ/çˆ†ç‚¸/æƒ¯æ€§çš„ååº”ã€‚"
    "ä¾‹å¦‚ï¼šé•¿å‘è¢«å¤§é£å‘åå¹èµ·ã€åˆ˜æµ·è´´åœ¨è„¸ä¸Šã€å¤–å¥—è¢«é£é¼“èµ·åˆè¢«å‹å›ã€ä¸‹æ‘†åœ¨å¥”è·‘æ—¶æœ‰å»¶è¿Ÿç”©åŠ¨æ„Ÿã€‚"
  ),

  "environment_detail_zh": (
    "ç”¨ 2ï½4 å¥ä¸­æ–‡ï¼ŒæŒ‰ç…§ å‰æ™¯ / ä¸­æ™¯ / èƒŒæ™¯ çš„å±‚æ¬¡ï¼Œå°½å¯èƒ½å…·ä½“åœ°æè¿°åœºæ™¯ç¯å¢ƒã€‚å¿…é¡»å†™å‡ºï¼š"
    "1ï¼‰ç©ºé—´ç±»å‹ï¼ˆå®¤å†…/å®¤å¤–ã€å¨æˆ¿/è¡—é“/ä»“åº“/åŠå…¬å®¤/å®‡å®™é£èˆ¹èˆ±å®¤ç­‰ï¼‰ï¼›"
    "2ï¼‰å‰æ™¯é è¿‘é•œå¤´çš„ç‰©ä½“å’Œè´¨æ„Ÿï¼ˆä¾‹å¦‚æ¡Œé¢ã€æ æ†ã€ç»ç’ƒã€å…‰å±ï¼Œå†™æ¸…é¢œè‰²/æè´¨/æ˜¯å¦è™šåŒ–ï¼‰ï¼›"
    "3ï¼‰ä¸­æ™¯ä¸»ä½“å‘¨å›´çš„ç¯å¢ƒç»“æ„ï¼ˆå¢™é¢ã€æŸœå­ã€æœºå™¨ã€è½¦è¾†ã€äººç¾¤ç­‰ï¼‰ï¼›"
    "4ï¼‰èƒŒæ™¯ä¸­å¯è¯†åˆ«çš„å»ºç­‘/å±±ä½“/åŸå¸‚å¤©é™…çº¿/çª—å¤–æ™¯è‰²ï¼›"
    "5ï¼‰åœ°é¢å’Œé¡¶éƒ¨çš„æ„Ÿè§‰ï¼ˆä¾‹å¦‚ï¼šæ°´æ³¥åœ°ã€æœ¨åœ°æ¿ã€å¸¦æ²¹æ±¡çš„ç“·ç –åœ°ã€è£¸éœ²ç®¡çº¿çš„å¤©èŠ±æ¿ï¼‰ã€‚"
    "ä¸è¦åªå†™â€œåœ¨ä¸€ä¸ªæˆ¿é—´é‡Œâ€ï¼Œå¿…é¡»å†™åˆ°èƒ½è®©ç¾æœ¯å¸ˆæŒ‰æ–‡å­—æ­æ™¯çš„ç¨‹åº¦ã€‚"
    "å¦‚ç”»é¢ä»¥å¤©ç©º/äº‘å±‚/æµ·é¢ç­‰ä¸ºä¸»ï¼Œä¹Ÿè¦å†™å‡ºäº‘å±‚å½¢æ€ã€æµ·æµªèµ°åŠ¿ã€è¿œå¤„åœ°è²Œç­‰ã€‚"
  ),

  "weather_force_detail_zh": (
    "å¦‚æœç”»é¢ä¸­æœ‰é£ã€é›¨ã€é›ªã€çˆ†ç‚¸å†²å‡»æ³¢ã€è½¦è¾†é«˜é€Ÿè¡Œé©¶å¸¦æ¥çš„æ°”æµç­‰ï¼Œè¯·ç”¨ 1ï½3 å¥ä¸­æ–‡å…·ä½“å†™å‡ºï¼š"
    "1ï¼‰è¿™äº›ç¯å¢ƒåŠ›æ¥è‡ªå“ªä¸ªæ–¹å‘ï¼ˆä¾‹å¦‚ï¼šä»å·¦ä¾§æ–œä¸Šæ–¹å¹æ¥ã€ä»äººç‰©èº«åæ¶Œæ¥ï¼‰ï¼›"
    "2ï¼‰å®ƒä»¬å¦‚ä½•ä½œç”¨åœ¨äººç‰©å’Œç¯å¢ƒä¸Šï¼ˆä¾‹å¦‚ï¼šé›¨ç‚¹æŠ½æ‰“åœ¨è„¸ä¸Šå’Œè¡£æœä¸Šã€é£æŠŠæ°´é¢å¹èµ·æµªèŠ±ï¼‰ï¼›"
    "3ï¼‰æ˜¯å¦é€ æˆæ˜æ˜¾æ™ƒåŠ¨ã€éœ‡åŠ¨æˆ–å…¶ä»–åé¦ˆã€‚è‹¥ç”»é¢æ²¡æœ‰æ˜æ˜¾ç¯å¢ƒåŠ›ï¼Œå¯å†™â€œæ— æ˜æ˜¾é£é›¨æˆ–ç¯å¢ƒå†²å‡»â€ã€‚"
  ),

  "props_and_tech_detail_zh": (
    "ç”¨ 1ï½3 å¥ä¸­æ–‡ï¼Œåˆ—å‡ºç”»é¢ä¸­æœ€é‡è¦çš„ 3ï½8 ä¸ªé“å…·/ç§‘æŠ€å…ƒç´ ï¼Œå¹¶è¯´æ˜å®ƒä»¬çš„å¤–è§‚ã€ä½ç½®å’ŒçŠ¶æ€ã€‚"
    "ä¾‹å¦‚ï¼šâ€œå·¦å‰æ™¯æ˜¯ä¸€ä¸ªé“¶è‰²ç¬”è®°æœ¬ç”µè„‘ï¼Œå±å¹•å‘å‡ºå†·è“è‰²å…‰ï¼›äººç‰©å³æ‰‹è¾¹æœ‰ä¸€å°é»‘è‰²å’–å•¡æœºï¼Œæœºèº«æœ‰æ°´æ¸åå…‰ï¼›"
    "èƒŒæ™¯å¢™ä¸ŠæŒ‚ç€ä¸¤å¹…æŠ½è±¡ç”»ï¼›å¤©ç©ºä¸­æœ‰ä¸¤æ¶æ— äººæœºä»å·¦å‘å³é£è¿‡ï¼›ç”»é¢å³ä¾§æ˜¯ä¸€å—åŠé€æ˜è“è‰²å…¨æ¯å±å¹•ï¼Œæ‚¬æµ®åœ¨ç©ºä¸­ï¼Œæ˜¾ç¤ºæ•°æ®å›¾è¡¨â€ã€‚"
  ),

  "physics_reaction_detail_zh": (
    "ç”¨ 1ï½3 å¥ä¸­æ–‡ï¼Œä¸“é—¨æè¿°â€œå—åŠ›â€ä¸â€œå½¢å˜â†’å›å¼¹â€çš„è¿‡ç¨‹ã€‚"
    "ä¾‹å¦‚ï¼šæ‹³å¤´ç ¸åœ¨äººç‰©è„¸ä¸Šå¯¼è‡´è„¸é¢Šè¢«æ˜æ˜¾æŒ¤å‹ã€ä¸‹å·´åç§»ï¼Œéšåè‚Œè‚‰æŠ–åŠ¨å¹¶ç¼“æ…¢å›å¼¹ï¼›"
    "æˆ–è€…è½¦è¾†æ’ä¸ŠæŠ¤æ æ—¶è½¦å¤´è¢«å‹æ‰ã€è½¦èº«æŠ–åŠ¨ã€äººç‰©èº«ä½“è¢«å®‰å…¨å¸¦æ‹‰æ‰¯åå¼¹å›ã€‚"
  ),

  "structure_damage_detail_zh": (
    "ç”¨ 1ï½3 å¥ä¸­æ–‡æè¿°ç‰©ä½“æˆ–ç»“æ„æœ¬èº«çš„æŸåæƒ…å†µï¼Œä¾‹å¦‚ï¼šè½¦å¤´é‡‘å±æŠ˜å ã€æŒ¡é£ç»ç’ƒå¼€è£‚ã€å»ºç­‘å¢™ä½“å¡Œé™·ã€æœºç¿¼æ–­è£‚ç­‰ï¼Œ"
    "å†™æ¸…â€œå“ªä¸€éƒ¨åˆ†â€å› æ’å‡»æˆ–çˆ†ç‚¸äº§ç”Ÿäº†æ€æ ·çš„å½¢å˜æˆ–ç ´æŸã€‚"
  ),

  "debris_motion_detail_zh": (
    "ç”¨ 1ï½3 å¥ä¸­æ–‡æè¿°ç¢ç‰‡/ç»ç’ƒæ¸£/é›¶ä»¶/çŸ³å—ç­‰é£æ•£çš„è½¨è¿¹å’ŒçŠ¶æ€ï¼š"
    "ä¾‹å¦‚ï¼šæŒ¡é£ç»ç’ƒç¢ç‰‡å‘å‰æ–¹å’Œå³ä¸Šæ–¹æŠ›æ´’ï¼Œå½¢æˆæ‰‡å½¢å¼§çº¿ï¼Œéšåè½åœ¨åœ°é¢ï¼›"
    "å»ºç­‘ç¢çŸ³å‘ä¸‹å è½æ—¶æ‰¬èµ·ç°å°˜ã€‚è‹¥ç”»é¢æ— æ˜æ˜¾ç¢ç‰‡é£æ•£ï¼Œå¯å†™â€œæ— æ˜æ˜¾ç¢ç‰‡é£æ•£â€ã€‚"
  ),

  "motion_detail_zh": (
    "ç”¨ 1ï½3 å¥ä¸­æ–‡ï¼Œä»â€œä¸Šä¸€ç¬é—´â†’å½“å‰ç¬é—´â†’ä¸‹ä¸€ç¬é—´â€çš„é¡ºåºï¼Œæè¿°è¿™ä¸€é•œå¤´æ‰€å±åŠ¨ä½œç‰‡æ®µã€‚"
    "å¦‚æœèƒ½ä»ç”»é¢æ¨æ–­å‡ºå¤§è‡´åŠ¨ä½œï¼Œè¯·å†™æ¸…ï¼šä¸Šä¸€ç¬é—´äººç‰©å¤§æ¦‚åœ¨åšä»€ä¹ˆï¼Œå½“å‰ç¬é—´ç”»é¢å®šæ ¼åœ¨ä»€ä¹ˆçŠ¶æ€ï¼Œä¸‹ä¸€ç¬é—´ææœ‰å¯èƒ½å‘ç”Ÿä»€ä¹ˆã€‚"
  ),

  "fx_detail_zh": (
    "å¦‚æœç”»é¢ä¸­æœ‰ç«èŠ±ã€çƒŸé›¾ã€å°˜åœŸã€èƒ½é‡æ³¢ã€é­”æ³•ç‰¹æ•ˆã€ç¢è£‚ç²’å­ç­‰ï¼Œè¯·ç”¨ 1ï½2 å¥ä¸­æ–‡æè¿°å®ƒä»¬çš„ä½ç½®ã€é¢œè‰²å’Œè¿åŠ¨æ–¹å‘ã€‚"
  ),

  "lighting_color_detail_zh": (
    "åœ¨ color_and_light_zh çš„åŸºç¡€ä¸Šï¼Œè¿›ä¸€æ­¥ç”¨ 1ï½2 å¥ä¸­æ–‡ç²¾ç»†æè¿°å…‰æºæ•°é‡ã€æ–¹å‘ã€è‰²æ¸©å·®å¼‚ã€"
    "æ˜¯å¦æœ‰é—ªç”µ/çˆ†å…‰/é¢‘é—ªç­‰ã€‚"
  ),

  "audio_cue_detail_zh": (
    "ç”¨ 1ï½3 å¥ä¸­æ–‡æè¿°è¿™ä¸€å¸§æ‰€åœ¨ç‰‡æ®µçš„å£°éŸ³è®¾è®¡ï¼š"
    "åŒ…æ‹¬ç¯å¢ƒå£°ï¼ˆé£å£°ã€é›¨å£°ã€è½¦è¾†å™ªéŸ³ã€æœºå™¨è¿è½¬ï¼‰ã€äººç‰©å°è¯ã€ç‰¹æ•ˆå£°ï¼ˆæ‰“å‡»å£°ã€çˆ†ç‚¸å£°ï¼‰ä»¥åŠ BGM çš„æƒ…ç»ªå’ŒèŠ‚å¥ç‚¹ã€‚"
  ),

  "edit_rhythm_detail_zh": (
    "ç”¨ 1ï½2 å¥ä¸­æ–‡æè¿°å‰ªè¾‘èŠ‚å¥å’Œæ—¶é—´å¤„ç†ï¼Œä¾‹å¦‚ï¼šæ­£å¸¸é€Ÿåº¦ã€è½»å¾®æ…¢åŠ¨ä½œã€å¤§å¹…æ…¢åŠ¨ä½œã€çªç„¶åŠ é€Ÿã€ç”©é•œè½¬åœºã€é—ªç™½è½¬åœºç­‰ã€‚"
  ),

  "midjourney_prompt": "ä¸€è¡Œè‹±æ–‡ Midjourney v6 æç¤ºè¯ï¼Œé€‚åˆç”Ÿæˆè¿™ä¸€å¸§çš„é™æ€åˆ†é•œå›¾",
  "midjourney_negative_prompt": "ä¸€è¡Œè‹±æ–‡è´Ÿé¢æç¤ºè¯ï¼Œä¾‹å¦‚ï¼štext, subtitle, watermark, extra fingers, deformed hands, distorted face, low resolution, blurry, cartoon, anime, painting",

  "video_prompt_en": (
    "ä¸€æ®µè‹±æ–‡è§†é¢‘æç¤ºè¯ï¼Œé€‚åˆç»™ SORA/VEO ä½¿ç”¨ã€‚ç”¨ 3-5 å¥æè¿°ï¼šäººç‰©å¤–è§‚ã€å½“å‰åŠ¨ä½œã€"
    "è¿é•œæ–¹å¼ï¼ˆè¦è¯´æ˜æ˜¯è¿½éšè§†è§’/ç¬¬ä¸€äººç§°/ä¾§å‘è·Ÿæ‹ç­‰ä»¥åŠé•œå¤´ç§»åŠ¨æ–¹å‘ï¼‰ã€"
    "ç¯å¢ƒåœ°å½¢ï¼ˆä¾‹å¦‚ winding coastal mountain road, steep cliff, ocean on the leftï¼‰ï¼Œä»¥åŠå…‰çº¿ä¸æ°›å›´ã€‚"
    "æœ€åä¸€å¥å†™æ¸…è¿™æ˜¯ä¸€æ®µå‡ ç§’é’Ÿçš„é•œå¤´ï¼Œä¾‹å¦‚ï¼š'4 second shot, vertical 9:16, 24fps, cinematic, highly detailed.'"
  )
}}

è¦æ±‚ï¼š
1. åªè¾“å‡ºä¸€ä¸ª JSON å¯¹è±¡ï¼Œä¸è¦ä»»ä½•è§£é‡Šæˆ–é¢å¤–æ–‡å­—ã€‚
2. æ‰€æœ‰å­—ç¬¦ä¸²å¿…é¡»ä½¿ç”¨åŒå¼•å·ï¼Œä¸è¦ä½¿ç”¨å•å¼•å·ã€‚
3. JSON ä¸­ä¸èƒ½æœ‰æ³¨é‡Šï¼Œä¸èƒ½æœ‰å¤šä½™çš„é€—å·ã€‚
"""
        resp = model.generate_content([prompt, img])
        text = _extract_text_from_response(resp)
        if not text:
            raise ValueError("æ¨¡å‹æœªè¿”å›æ–‡æœ¬")

        start = text.find("{")
        end = text.rfind("}")
        if start == -1 or end == -1 or end <= start:
            raise ValueError("æœªæ£€æµ‹åˆ°æœ‰æ•ˆ JSON ç»“æ„")

        json_str = text[start : end + 1]
        info = json.loads(json_str)

        info["index"] = index
        info.setdefault("scene_description_zh", "")
        info.setdefault("tags_zh", [])
        info.setdefault("camera", {})
        info.setdefault("color_and_light_zh", "")
        info.setdefault("mood_zh", "")
        info.setdefault("characters", [])
        info.setdefault("character_action_detail_zh", "")
        info.setdefault("face_expression_detail_zh", "")
        info.setdefault("cloth_hair_reaction_zh", "")
        info.setdefault("environment_detail_zh", "")
        info.setdefault("weather_force_detail_zh", "")
        info.setdefault("props_and_tech_detail_zh", "")
        info.setdefault("physics_reaction_detail_zh", "")
        info.setdefault("structure_damage_detail_zh", "")
        info.setdefault("debris_motion_detail_zh", "")
        info.setdefault("motion_detail_zh", "")
        info.setdefault("fx_detail_zh", "")
        info.setdefault("lighting_color_detail_zh", "")
        info.setdefault("audio_cue_detail_zh", "")
        info.setdefault("edit_rhythm_detail_zh", "")
        info.setdefault("midjourney_prompt", "")
        info.setdefault("midjourney_negative_prompt", "")
        info.setdefault("video_prompt_en", "")

        cam = info["camera"]
        cam.setdefault("shot_type_zh", "")
        cam.setdefault("shot_type", "")
        cam.setdefault("angle_zh", "")
        cam.setdefault("angle", "")
        cam.setdefault("movement_zh", "")
        cam.setdefault("movement", "")
        cam.setdefault("composition_zh", "")
        cam.setdefault("composition", "")

        return info

    except Exception as e:
        return {
            "index": index,
            "scene_description_zh": f"ï¼ˆAI åˆ†æå¤±è´¥ï¼š{e}ï¼‰",
            "tags_zh": [],
            "camera": {
                "shot_type_zh": "",
                "shot_type": "",
                "angle_zh": "",
                "angle": "",
                "movement_zh": "",
                "movement": "",
                "composition_zh": "",
                "composition": "",
            },
            "color_and_light_zh": "",
            "mood_zh": "",
            "characters": [],
            "character_action_detail_zh": "",
            "face_expression_detail_zh": "",
            "cloth_hair_reaction_zh": "",
            "environment_detail_zh": "",
            "weather_force_detail_zh": "",
            "props_and_tech_detail_zh": "",
            "physics_reaction_detail_zh": "",
            "structure_damage_detail_zh": "",
            "debris_motion_detail_zh": "",
            "motion_detail_zh": "",
            "fx_detail_zh": "",
            "lighting_color_detail_zh": "",
            "audio_cue_detail_zh": "",
            "edit_rhythm_detail_zh": "",
            "midjourney_prompt": "",
            "midjourney_negative_prompt": "",
            "video_prompt_en": "",
        }


def analyze_images_concurrently(
    images: List[Image.Image], model, max_ai_frames: int
) -> List[Dict[str, Any]]:
    """
    å¹¶å‘åˆ†æå¤šå¼ å›¾ç‰‡ã€‚
    åªå¯¹å‰ max_ai_frames å¸§åš AI è°ƒç”¨ï¼Œå…¶ä½™å¸§ç”¨å ä½è¯´æ˜ã€‚
    """
    n = len(images)
    if n == 0:
        return []

    use_n = min(max_ai_frames, n)
    results: List[Dict[str, Any]] = [None] * n  # type: ignore

    status = st.empty()
    status.info(f"âš¡ æ­£åœ¨å¯¹å‰ {use_n} å¸§è¿›è¡Œ AI åˆ†æï¼ˆå…± {n} å¸§ï¼‰ï¼Œå…¶ä½™å¸§ä¿ç•™æˆªå›¾ä¸è‰²å¡ã€‚")

    with concurrent.futures.ThreadPoolExecutor(max_workers=min(use_n, 6)) as executor:
        future_to_index = {
            executor.submit(analyze_single_image, images[i], model, i + 1): i
            for i in range(use_n)
        }
        for future in concurrent.futures.as_completed(future_to_index):
            i = future_to_index[future]
            try:
                results[i] = future.result()
            except Exception as e:
                results[i] = {
                    "index": i + 1,
                    "scene_description_zh": f"ï¼ˆAI åˆ†æå¤±è´¥ï¼š{e}ï¼‰",
                    "tags_zh": [],
                    "camera": {
                        "shot_type_zh": "",
                        "shot_type": "",
                        "angle_zh": "",
                        "angle": "",
                        "movement_zh": "",
                        "movement": "",
                        "composition_zh": "",
                        "composition": "",
                    },
                    "color_and_light_zh": "",
                    "mood_zh": "",
                    "characters": [],
                    "character_action_detail_zh": "",
                    "face_expression_detail_zh": "",
                    "cloth_hair_reaction_zh": "",
                    "environment_detail_zh": "",
                    "weather_force_detail_zh": "",
                    "props_and_tech_detail_zh": "",
                    "physics_reaction_detail_zh": "",
                    "structure_damage_detail_zh": "",
                    "debris_motion_detail_zh": "",
                    "motion_detail_zh": "",
                    "fx_detail_zh": "",
                    "lighting_color_detail_zh": "",
                    "audio_cue_detail_zh": "",
                    "edit_rhythm_detail_zh": "",
                    "midjourney_prompt": "",
                    "midjourney_negative_prompt": "",
                    "video_prompt_en": "",
                }

    for i in range(use_n, n):
        results[i] = {
            "index": i + 1,
            "scene_description_zh": "ï¼ˆæœ¬å¸§æœªåš AI åˆ†æï¼Œç”¨äºèŠ‚çœå½“å‰ API é…é¢ï¼Œä½†ä»å¯ç”¨äºè§†è§‰å‚è€ƒå’Œè‰²å¡ã€‚ï¼‰",
            "tags_zh": [],
            "camera": {
                "shot_type_zh": "",
                "shot_type": "",
                "angle_zh": "",
                "angle": "",
                "movement_zh": "",
                "movement": "",
                "composition_zh": "",
                "composition": "",
            },
            "color_and_light_zh": "",
            "mood_zh": "",
            "characters": [],
            "character_action_detail_zh": "",
            "face_expression_detail_zh": "",
            "cloth_hair_reaction_zh": "",
            "environment_detail_zh": "",
            "weather_force_detail_zh": "",
            "props_and_tech_detail_zh": "",
            "physics_reaction_detail_zh": "",
            "structure_damage_detail_zh": "",
            "debris_motion_detail_zh": "",
            "motion_detail_zh": "",
            "fx_detail_zh": "",
            "lighting_color_detail_zh": "",
            "audio_cue_detail_zh": "",
            "edit_rhythm_detail_zh": "",
            "midjourney_prompt": "",
            "midjourney_negative_prompt": "",
            "video_prompt_en": "",
        }

    status.empty()
    return results


# ========================
# æ•´ä½“è§†é¢‘å±‚é¢çš„æ€»ç»“
# ========================

def analyze_overall_video(frame_infos: List[Dict[str, Any]], model) -> str:
    described = [
        info
        for info in frame_infos
        if info.get("scene_description_zh")
        and "æœªåš AI åˆ†æ" not in info["scene_description_zh"]
        and "AI åˆ†æå¤±è´¥" not in info["scene_description_zh"]
    ]
    if not described:
        return "ï¼ˆæš‚æœªè·å–åˆ°æœ‰æ•ˆçš„å¸§çº§åˆ†æï¼Œæ— æ³•ç”Ÿæˆæ•´ä½“å‰§æƒ…å¤§çº²ã€‚ï¼‰"

    parts = []
    for info in described:
        idx = info["index"]
        cam = info.get("camera", {})
        tags = info.get("tags_zh", [])
        part = (
            f"ç¬¬ {idx} å¸§ï¼š{info.get('scene_description_zh', '')}\n"
            f"æ™¯åˆ«ï¼š{cam.get('shot_type_zh', '')}ï¼›è§’åº¦ï¼š{cam.get('angle_zh', '')}ï¼›è¿é•œï¼š{cam.get('movement_zh', '')}ï¼›æ„å›¾ï¼š{cam.get('composition_zh', '')}\n"
            f"è‰²å½©ä¸å…‰å½±ï¼š{info.get('color_and_light_zh', '')}\n"
            f"æƒ…ç»ªæ°›å›´ï¼š{info.get('mood_zh', '')}\n"
            f"æ ‡ç­¾ï¼š{'ã€'.join(tags)}"
        )
        parts.append(part)

    joined = "\n\n".join(parts)

    prompt = f"""
ä½ ç°åœ¨æ˜¯èµ„æ·±è§†é¢‘å¯¼æ¼” + å‰ªè¾‘å¸ˆ + çŸ­è§†é¢‘è¿è¥ä¸“å®¶ + å†…å®¹åˆè§„å®¡æ ¸å‘˜ã€‚
ä¸‹é¢æ˜¯ä»ä¸€æ®µè§†é¢‘ä¸­æŠ½å–çš„è‹¥å¹²å…³é”®å¸§çš„è¯¦ç»†è¯´æ˜ï¼Œè¯·ä½ åŸºäºè¿™äº›è¯´æ˜ï¼Œå¯¹æ•´æ®µè§†é¢‘åšæ•´ä½“åˆ†æã€‚

=== å¸§çº§è¯´æ˜å¼€å§‹ ===
{joined}
=== å¸§çº§è¯´æ˜ç»“æŸ ===

è¯·ä¸¥æ ¼æŒ‰ä¸‹é¢ç»“æ„è¾“å‡ºä¸­æ–‡åˆ†æï¼š

ã€å‰§æƒ…å¤§çº²ã€‘
ç”¨ 2-4 å¥æ¦‚æ‹¬è¿™æ®µè§†é¢‘çš„å¤§è‡´å†…å®¹/äººç‰©å…³ç³»/å‘ç”Ÿåœºæ™¯ã€‚

ã€æ•´ä½“è§†å¬é£æ ¼ã€‘
ä»èŠ‚å¥å¿«æ…¢ã€é•œå¤´æ„Ÿã€è‰²å½©æ°”è´¨ï¼ˆæš–/å†·/æ—¥å¸¸/æ¢¦å¹»ï¼‰ã€æƒ…ç»ªæ°›å›´ç­‰è§’åº¦æ€»ç»“æ•´ä½“é£æ ¼ã€‚

ã€é€‚åˆçš„è¯é¢˜æ ‡ç­¾ã€‘
ç”¨ #æ ‡ç­¾ å½¢å¼ç»™å‡º 5-10 ä¸ªï¼Œé€‚åˆæŠ–éŸ³/å°çº¢ä¹¦/è§†é¢‘å·ç­‰å¹³å°ã€‚

ã€å•†ä¸šä¸åˆè§„é£é™©ã€‘
ä»â€œè¡€è…¥/æš´åŠ›/è‰²æƒ…/æ”¿æ²»/å“ç‰Œå•†æ ‡â€ç­‰ç»´åº¦ï¼Œç®€å•è¯„ä¼°ï¼š
æ•´ä½“é£é™©çº§åˆ«ï¼šä½ / ä¸­ / é«˜
å¹¶ç”¨ 2-3 å¥è¯è¯´æ˜éœ€è¦æ³¨æ„çš„ç‚¹ã€‚

è¯·ç›´æ¥è¾“å‡ºä»¥ä¸Š 4 ä¸ªå°èŠ‚ï¼Œä¸è¦æ·»åŠ é¢å¤–è¯´æ˜ã€‚
"""
    try:
        resp = model.generate_content(prompt)
        return _extract_text_from_response(resp)
    except Exception as e:
        msg = str(e)
        if "quota" in msg or "You exceeded your current quota" in msg:
            return "æ•´ä½“åˆ†æå¤±è´¥ï¼šå½“å‰ Gemini å…è´¹é¢åº¦çš„æ¯åˆ†é’Ÿè°ƒç”¨æ¬¡æ•°å·²ç”¨å®Œï¼Œè¯·ç¨ç­‰å‡ åç§’æˆ–å‡å°‘æœ¬æ¬¡åˆ†æå¸§æ•°åé‡è¯•ã€‚"
        return f"æ•´ä½“åˆ†æå¤±è´¥ï¼š{msg}"


# ========================
# 10 ç§’å¹¿å‘Šæ—ç™½è„šæœ¬ç”Ÿæˆ
# ========================

def generate_ad_script(frame_infos: List[Dict[str, Any]], model) -> str:
    described = [
        info
        for info in frame_infos
        if info.get("scene_description_zh")
        and "æœªåš AI åˆ†æ" not in info["scene_description_zh"]
        and "AI åˆ†æå¤±è´¥" not in info["scene_description_zh"]
    ]
    if not described:
        return "ï¼ˆæš‚æœªè·å–åˆ°æœ‰æ•ˆçš„å¸§çº§åˆ†æï¼Œæ— æ³•ç”Ÿæˆå¹¿å‘Šæ—ç™½è„šæœ¬ã€‚ï¼‰"

    parts = []
    for info in described:
        idx = info["index"]
        tags = info.get("tags_zh", [])
        parts.append(
            f"ç¬¬ {idx} å¸§ï¼š{info.get('scene_description_zh', '')}ï¼›æ ‡ç­¾ï¼š{'ã€'.join(tags)}"
        )
    joined = "\n".join(parts)

    prompt = f"""
ä½ æ˜¯ä¸€åèµ„æ·±å¹¿å‘Šå¯¼æ¼” + æ–‡æ¡ˆã€‚
æˆ‘æœ‰ä¸€ä¸ªç”±è‹¥å¹²ç”»é¢ç»„æˆçš„ç«–ç‰ˆçŸ­è§†é¢‘ï¼Œæ—¶é•¿å¤§çº¦ 8-12 ç§’ã€‚
ä¸‹é¢æ˜¯æ¯ä¸ªç”»é¢çš„ç®€è¦è¯´æ˜ï¼Œè¯·ä½ åŸºäºè¿™äº›ä¿¡æ¯ï¼Œå†™ä¸€æ¡é€‚åˆé…åˆè¿™äº›ç”»é¢æ’­æ”¾çš„ä¸­æ–‡å¹¿å‘Šæ—ç™½è„šæœ¬ã€‚

=== å…³é”®å¸§æ¦‚è§ˆ ===
{joined}
=== å…³é”®å¸§æ¦‚è§ˆç»“æŸ ===

è¦æ±‚ï¼š
1. æ—ç™½æ€»æ—¶é•¿æ§åˆ¶åœ¨ 8-12 ç§’å·¦å³ï¼ˆæ­£å¸¸è¯­é€Ÿï¼‰ï¼Œæ–‡æœ¬ 35-70 å­—å³å¯ã€‚
2. é£æ ¼ä¸ç”»é¢è°ƒæ€§åŒ¹é…ã€‚
3. ç”¨è‡ªç„¶å£è¯­åŒ–ä¸­æ–‡ï¼Œä¸è¦å‡ºç°â€œç”»é¢ä¸­â€â€œé•œå¤´é‡Œâ€å­—çœ¼ã€‚

è¯·ä¸¥æ ¼æŒ‰ç…§ä¸‹é¢æ ¼å¼è¾“å‡ºï¼š

ã€10ç§’å¹¿å‘Šæ—ç™½è„šæœ¬ã€‘
ï¼ˆåœ¨è¿™é‡Œå†™å®Œæ•´çš„ä¸€æ®µæ—ç™½ï¼‰

ä¸è¦è¾“å‡ºå…¶ä»–ä»»ä½•å†…å®¹ã€‚
"""
    try:
        resp = model.generate_content(prompt)
        return _extract_text_from_response(resp)
    except Exception as e:
        msg = str(e)
        if "quota" in msg or "You exceeded your current quota" in msg:
            return "å¹¿å‘Šæ–‡æ¡ˆç”Ÿæˆå¤±è´¥ï¼šå½“å‰ Gemini å…è´¹é¢åº¦çš„æ¯åˆ†é’Ÿè°ƒç”¨æ¬¡æ•°å·²ç”¨å®Œï¼Œè¯·ç¨ç­‰å‡ åç§’æˆ–å‡å°‘æœ¬æ¬¡åˆ†æå¸§æ•°åé‡è¯•ã€‚"
        return f"å¹¿å‘Šæ–‡æ¡ˆç”Ÿæˆå¤±è´¥ï¼š{msg}"


# ========================
# æ—¶é—´è½´åˆ†é•œè„šæœ¬ç”Ÿæˆï¼ˆçº¯æ‹¼æ¥ç‰ˆï¼‰
# ========================

def generate_timeline_shotlist(
    frame_infos: List[Dict[str, Any]],
    used_range: Tuple[float, float],
) -> str:
    """
    ä¸å†è°ƒç”¨ AIï¼Œæ€»ç»“ = æŠŠæ¯å¸§åˆ†æåˆ°çš„æ‰€æœ‰å†…å®¹ç»“æ„åŒ–æ¬åˆ°æ—¶é—´è½´é‡Œã€‚

    æ—¶é—´è½´åˆ†æ®µè§„åˆ™ï¼š
    - ä» 0 å¼€å§‹è®¡æ—¶ï¼Œä»¥åˆ†æåŒºé—´é•¿åº¦ / å¸§æ•° å‡åˆ†æ¯æ®µæ—¶é•¿
    - ç¬¬ i å¸§å¯¹åº”æ—¶é—´æ®µ [t_i, t_{i+1}]ï¼Œå°½é‡ä¿è¯æ®µè½è¿ç»­ã€ä¸é‡å 
    """
    n = len(frame_infos)
    if n == 0:
        return "ï¼ˆæš‚æ— å…³é”®å¸§ï¼Œæ— æ³•ç”Ÿæˆæ—¶é—´è½´åˆ†é•œè„šæœ¬ã€‚ï¼‰"

    start_used, end_used = used_range
    total_len = max(0.1, end_used - start_used)
    seg = total_len / n

    lines: List[str] = []

    for i, info in enumerate(frame_infos):
        t0 = i * seg
        t1 = (i + 1) * seg
        if i == n - 1:
            t1 = total_len

        shot_id = f"S{i+1:02d}"

        cam = info.get("camera", {}) or {}
        tags = info.get("tags_zh", []) or []

        scene = (info.get("scene_description_zh") or "").strip()
        char_act = (info.get("character_action_detail_zh") or "").strip()
        env = (info.get("environment_detail_zh") or "").strip()
        props = (info.get("props_and_tech_detail_zh") or "").strip()
        motion = (info.get("motion_detail_zh") or "").strip()
        mood = (info.get("mood_zh") or "").strip()

        shot_type = cam.get("shot_type_zh", "")
        angle = cam.get("angle_zh", "")
        movement = cam.get("movement_zh", "")
        composition = cam.get("composition_zh", "")

        face = (info.get("face_expression_detail_zh") or "").strip()
        cloth_hair = (info.get("cloth_hair_reaction_zh") or "").strip()
        weather = (info.get("weather_force_detail_zh") or "").strip()
        physics = (info.get("physics_reaction_detail_zh") or "").strip()
        structure_damage = (info.get("structure_damage_detail_zh") or "").strip()
        debris_motion = (info.get("debris_motion_detail_zh") or "").strip()
        fx = (info.get("fx_detail_zh") or "").strip()
        lighting = (info.get("lighting_color_detail_zh") or "").strip()
        audio = (info.get("audio_cue_detail_zh") or "").strip()
        edit = (info.get("edit_rhythm_detail_zh") or "").strip()

        block_lines: List[str] = []
        block_lines.append(f"ã€{shot_id} | {t0:.1f}-{t1:.1f} ç§’ã€‘")

        if scene:
            block_lines.append(f"ç”»é¢å†…å®¹ï¼š{scene}")
        if char_act:
            block_lines.append(f"äººç‰©åŠ¨ä½œï¼š{char_act}")
        if face:
            block_lines.append(f"é¢éƒ¨ä¸çœ¼ç¥ï¼š{face}")
        if cloth_hair:
            block_lines.append(f"æœè£…ä¸å¤´å‘ï¼š{cloth_hair}")

        if env:
            block_lines.append(f"åœºæ™¯ä¸ç©ºé—´ï¼š{env}")
        if weather:
            block_lines.append(f"å¤©æ°”ä¸ç¯å¢ƒåŠ›ï¼š{weather}")

        if props:
            block_lines.append(f"é“å…·ä¸ç§‘æŠ€ï¼š{props}")
        if structure_damage:
            block_lines.append(f"ç»“æ„æŸåï¼š{structure_damage}")
        if debris_motion:
            block_lines.append(f"ç¢ç‰‡ä¸é£æ•£è½¨è¿¹ï¼š{debris_motion}")
        if physics:
            block_lines.append(f"å—åŠ›ä¸ç‰©ç†åé¦ˆï¼š{physics}")

        if fx:
            block_lines.append(f"ç‰¹æ•ˆä¸ç²’å­ï¼š{fx}")
        if lighting:
            block_lines.append(f"å…‰çº¿ä¸è‰²å½©ï¼š{lighting}")

        cam_desc_parts = []
        if shot_type:
            cam_desc_parts.append(f"æ™¯åˆ«ï¼š{shot_type}")
        if angle:
            cam_desc_parts.append(f"è§’åº¦ï¼š{angle}")
        if movement:
            cam_desc_parts.append(f"è¿é•œï¼š{movement}")
        if composition:
            cam_desc_parts.append(f"æ„å›¾ï¼š{composition}")
        if cam_desc_parts:
            block_lines.append("æœºä½ä¸è¿åŠ¨ï¼š" + "ï¼›".join(cam_desc_parts))

        if mood:
            block_lines.append(f"æƒ…ç»ªæ°›å›´ï¼š{mood}")
        if motion:
            block_lines.append(f"åŠ¨ä½œè¶‹åŠ¿ï¼š{motion}")

        if audio:
            block_lines.append(f"å£°éŸ³ä¸èŠ‚å¥ï¼š{audio}")
        if edit:
            block_lines.append(f"å‰ªè¾‘ä¸èŠ‚å¥ï¼š{edit}")

        if tags:
            block_lines.append("æ ‡ç­¾ï¼š" + " ".join(tags))

        lines.append("\n".join(block_lines))

    return "\n\n".join(lines)


# ========================
# ä¾§è¾¹æ ï¼šAPI Key & å‚æ•°è®¾ç½®
# ========================

with st.sidebar:
    st.header("ğŸ”‘ ç¬¬ä¸€æ­¥ï¼šé…ç½® Gemini API Key")
    api_key = st.text_input(
        "è¾“å…¥ Google API Key",
        type="password",
        value=st.session_state["api_key"],
        help="ç²˜è´´ä½ çš„ Gemini API Keyï¼ˆé€šå¸¸ä»¥ AIza å¼€å¤´ï¼‰",
    )
    st.session_state["api_key"] = api_key

    st.markdown("---")
    max_ai_frames = st.slider(
        "æœ¬æ¬¡æœ€å¤šåš AI åˆ†æçš„å¸§æ•°ï¼ˆæ¶ˆè€—é…é¢ï¼‰",
        min_value=4,
        max_value=20,
        value=10,
        step=1,
    )
    st.caption("å»ºè®®ï¼š10 ç§’è§†é¢‘ 6~10 å¸§å³å¯ï¼›è¶…å‡ºéƒ¨åˆ†ä»ä¼šæ˜¾ç¤ºæˆªå›¾å’Œè‰²å¡ï¼Œä½†ä¸è°ƒ AIã€‚")

    st.markdown("---")
    st.markdown("â± åˆ†ææ—¶é—´èŒƒå›´ï¼ˆå•ä½ï¼šç§’ï¼‰")
    start_sec = st.number_input(
        "ä»ç¬¬å‡ ç§’å¼€å§‹ï¼ˆå«ï¼‰", min_value=0.0, value=0.0, step=0.5,
        help="ç²¾ç¡®åˆ° 0.5 ç§’ï¼›é»˜è®¤ 0 è¡¨ç¤ºä»å¤´å¼€å§‹"
    )
    end_sec = st.number_input(
        "åˆ°ç¬¬å‡ ç§’ç»“æŸï¼ˆ0 æˆ– â‰¤å¼€å§‹ç§’ è¡¨ç¤ºç›´åˆ°ç»“å°¾ï¼‰",
        min_value=0.0, value=0.0, step=0.5,
        help="ä¾‹å¦‚ï¼šåªåˆ†æ 3~8 ç§’ï¼Œå°±å¡« 3 å’Œ 8ï¼›å¡« 0 æˆ–ä¸å¤§äºå¼€å§‹ç§’åˆ™åˆ†æåˆ°ç»“å°¾"
    )

    if not api_key:
        st.warning("ğŸ”´ è¿˜æ²¡æœ‰ Keyï¼Œå…ˆå» https://ai.google.dev/ ç”³è¯·ä¸€ä¸ª")
    else:
        st.success("ğŸŸ¢ Key å·²å°±ç»ª")


# ========================
# åˆå§‹åŒ– Gemini æ¨¡å‹
# ========================

model = None
if api_key:
    try:
        genai.configure(api_key=api_key)
        model = genai.GenerativeModel(GEMINI_MODEL_NAME)
    except Exception as e:
        st.error(f"âŒ åˆå§‹åŒ– Gemini æ¨¡å‹å¤±è´¥ï¼š{e}")
        model = None


# ========================
# ä¸»æµç¨‹ï¼šä¸Šä¼ /é“¾æ¥ é€‰æ‹© + æŠ½å¸§ + åˆ†æ + å¸ƒå±€å±•ç¤º
# ========================

source_mode = st.radio(
    "ğŸ“¥ é€‰æ‹©è§†é¢‘æ¥æº",
    ["ä¸Šä¼ æœ¬åœ°æ–‡ä»¶", "è¾“å…¥ç½‘ç»œè§†é¢‘é“¾æ¥ï¼ˆæŠ–éŸ³ / Bç«™ / TikTok / YouTubeï¼‰"],
    index=0,
)

video_url: Optional[str] = None
uploaded_file = None

if source_mode == "ä¸Šä¼ æœ¬åœ°æ–‡ä»¶":
    uploaded_file = st.file_uploader(
        "ğŸ“‚ ä¸Šä¼ è§†é¢‘æ–‡ä»¶ï¼ˆå»ºè®® < 50MBï¼‰",
        type=["mp4", "mov", "m4v", "avi", "mpeg"],
    )
else:
    video_url = st.text_input(
        "ğŸ”— è¾“å…¥è§†é¢‘é“¾æ¥",
        placeholder="ä¾‹å¦‚ï¼šhttps://v.douyin.com/xxxxxx æˆ– https://www.douyin.com/video/xxxxxxxxx",
    )

if st.button("ğŸš€ ä¸€é”®è§£ææ•´æ¡è§†é¢‘"):
    if not api_key or model is None:
        st.error("è¯·å…ˆåœ¨å·¦ä¾§è¾“å…¥æœ‰æ•ˆçš„ Google API Keyã€‚")
    else:
        tmp_path: Optional[str] = None
        source_label = ""
        source_type = ""

        try:
            # 1. å‡†å¤‡è§†é¢‘è·¯å¾„
            if source_mode == "ä¸Šä¼ æœ¬åœ°æ–‡ä»¶":
                source_type = "upload"
                if not uploaded_file:
                    st.error("è¯·å…ˆä¸Šä¼ ä¸€ä¸ªè§†é¢‘æ–‡ä»¶ã€‚")
                    st.stop()
                suffix = os.path.splitext(uploaded_file.name)[1] or ".mp4"
                with tempfile.NamedTemporaryFile(delete=False, suffix=suffix) as tmp:
                    tmp.write(uploaded_file.read())
                    tmp_path = tmp.name
                source_label = uploaded_file.name
            else:
                source_type = "url"
                if not video_url:
                    st.error("è¯·è¾“å…¥ä¸€ä¸ªæœ‰æ•ˆçš„è§†é¢‘é“¾æ¥ã€‚")
                    st.stop()
                st.info("ğŸŒ æ­£åœ¨ä»ç½‘ç»œä¸‹è½½è§†é¢‘ï¼Œè¯·ç¨å€™...")
                tmp_path = download_video_from_url(video_url)
                source_label = video_url

            if not tmp_path:
                st.error("è§†é¢‘è·¯å¾„å¼‚å¸¸ï¼Œè¯·é‡è¯•ã€‚")
            else:
                # 2. æŠ½å¸§ï¼ˆå¸¦æ—¶é—´åŒºé—´ï¼‰
                st.info("â³ æ­£åœ¨æ ¹æ®æŒ‡å®šæ—¶é—´åŒºé—´è‡ªåŠ¨æŠ½å–å…³é”®å¸§...")
                images, duration, used_range = extract_keyframes_dynamic(
                    tmp_path,
                    start_sec=start_sec,
                    end_sec=end_sec if end_sec > 0 else None,
                )
                start_used, end_used = used_range

                try:
                    os.remove(tmp_path)
                except OSError:
                    pass

                if not images:
                    st.error("âŒ æ— æ³•ä»è§†é¢‘ä¸­è¯»å–å¸§ï¼Œè¯·æ£€æŸ¥è§†é¢‘æ˜¯å¦æŸåæˆ–æ ¼å¼å¼‚å¸¸ã€‚")
                    st.stop()

                st.success(
                    f"âœ… å·²æˆåŠŸæŠ½å– {len(images)} ä¸ªå…³é”®å¸§ï¼ˆè§†é¢‘æ€»é•¿çº¦ {duration:.1f} ç§’ï¼Œ"
                    f"æœ¬æ¬¡åˆ†æåŒºé—´ï¼š{start_used:.1f}â€“{end_used:.1f} ç§’ï¼‰ã€‚"
                )

                # 3. ä¸»è‰²è°ƒ
                frame_palettes: List[List[Tuple[int, int, int]]] = []
                for img in images:
                    try:
                        palette_colors = get_color_palette(img, num_colors=5)
                    except Exception:
                        palette_colors = []
                    frame_palettes.append(palette_colors)

                # â­ æ§åˆ¶æœ¬æ¬¡ AI è°ƒç”¨æ€»æ•°ä¸è¶…è¿‡å…è´¹ 10 æ¬¡
                overhead_calls = 2  # æ•´ä½“ + å¹¿å‘Šæ–‡æ¡ˆ
                max_ai_frames_safe = max(
                    1,
                    min(max_ai_frames, FREE_TIER_RPM_LIMIT - overhead_calls),
                )
                if max_ai_frames_safe < max_ai_frames:
                    st.info(
                        f"ä¸ºé¿å…è§¦å‘å…è´¹é¢åº¦é™åˆ¶ï¼Œæœ¬æ¬¡åªå¯¹ **å‰ {max_ai_frames_safe} å¸§** åš AI åˆ†æ "
                        f"ï¼ˆä¾§è¾¹æ è®¾ç½®ä¸º {max_ai_frames} å¸§ï¼‰ã€‚"
                    )

                # 4. å¸§çº§åˆ†æ
                with st.spinner("ğŸ§  æ­£åœ¨ä¸ºå…³é”®å¸§ç”Ÿæˆç»“æ„åŒ–åˆ†æ + MJ æç¤ºè¯ + è§†é¢‘æç¤ºè¯..."):
                    frame_infos = analyze_images_concurrently(
                        images, model, max_ai_frames=max_ai_frames_safe
                    )

                # 5. æ•´ä½“åˆ†æ + å¹¿å‘Šæ–‡æ¡ˆ + æ—¶é—´è½´åˆ†é•œï¼ˆæ—¶é—´è½´ä¸ºçº¯æ‹¼æ¥ï¼‰
                with st.spinner("ğŸ“š æ­£åœ¨ç”Ÿæˆæ•´æ®µè§†é¢‘çš„å‰§æƒ…å¤§çº²ä¸è¯é¢˜æ ‡ç­¾..."):
                    overall = analyze_overall_video(frame_infos, model)
                with st.spinner("ğŸ¤ æ­£åœ¨ç”Ÿæˆ 10 ç§’å¹¿å‘Šæ—ç™½è„šæœ¬..."):
                    ad_script = generate_ad_script(frame_infos, model)
                with st.spinner("ğŸ¬ æ­£åœ¨ç”Ÿæˆæ—¶é—´è½´åˆ†é•œè„šæœ¬ï¼ˆçº¯æ‹¼æ¥ç‰ˆï¼‰..."):
                    timeline_shotlist = generate_timeline_shotlist(
                        frame_infos, used_range=used_range
                    )

                # 6. ç»„è£… export_data + å†™å…¥å†å²è®°å½•
                export_frames = []
                for info, palette in zip(frame_infos, frame_palettes):
                    export_frames.append(
                        {
                            "index": info.get("index"),
                            "scene_description_zh": info.get("scene_description_zh", ""),
                            "tags_zh": info.get("tags_zh", []),
                            "camera": info.get("camera", {}),
                            "color_and_light_zh": info.get("color_and_light_zh", ""),
                            "mood_zh": info.get("mood_zh", ""),
                            "characters": info.get("characters", []),
                            "character_action_detail_zh": info.get("character_action_detail_zh", ""),
                            "face_expression_detail_zh": info.get("face_expression_detail_zh", ""),
                            "cloth_hair_reaction_zh": info.get("cloth_hair_reaction_zh", ""),
                            "environment_detail_zh": info.get("environment_detail_zh", ""),
                            "weather_force_detail_zh": info.get("weather_force_detail_zh", ""),
                            "props_and_tech_detail_zh": info.get("props_and_tech_detail_zh", ""),
                            "physics_reaction_detail_zh": info.get("physics_reaction_detail_zh", ""),
                            "structure_damage_detail_zh": info.get("structure_damage_detail_zh", ""),
                            "debris_motion_detail_zh": info.get("debris_motion_detail_zh", ""),
                            "motion_detail_zh": info.get("motion_detail_zh", ""),
                            "fx_detail_zh": info.get("fx_detail_zh", ""),
                            "lighting_color_detail_zh": info.get("lighting_color_detail_zh", ""),
                            "audio_cue_detail_zh": info.get("audio_cue_detail_zh", ""),
                            "edit_rhythm_detail_zh": info.get("edit_rhythm_detail_zh", ""),
                            "midjourney_prompt": info.get("midjourney_prompt", ""),
                            "midjourney_negative_prompt": info.get("midjourney_negative_prompt", ""),
                            "video_prompt_en": info.get("video_prompt_en", ""),
                            "palette_rgb": [list(c) for c in (palette or [])],
                            "palette_hex": [rgb_to_hex(c) for c in (palette or [])],
                        }
                    )

                export_data = {
                    "meta": {
                        "model": GEMINI_MODEL_NAME,
                        "frame_count": len(images),
                        "max_ai_frames_this_run": max_ai_frames_safe,
                        "duration_sec_est": duration,
                        "start_sec_used": start_used,
                        "end_sec_used": end_used,
                        "source_type": source_type,
                        "source_label": source_label,
                    },
                    "frames": export_frames,
                    "overall_analysis": overall,
                    "ad_script_10s": ad_script,
                    "timeline_shotlist_zh": timeline_shotlist,
                }

                json_str = json.dumps(export_data, ensure_ascii=False, indent=2)

                history = st.session_state["analysis_history"]
                run_id = f"run_{len(history) + 1}"
                history.append(
                    {
                        "id": run_id,
                        "created_at": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                        "meta": export_data["meta"],
                        "data": export_data,
                    }
                )
                st.session_state["analysis_history"] = history

                # 7. Tabs å±•ç¤º
                tab_frames, tab_story, tab_json, tab_history = st.tabs(
                    [
                        "ğŸ å…³é”®å¸§ & æç¤ºè¯",
                        "ğŸ“š å‰§æƒ…æ€»ç»“ & å¹¿å‘Šæ—ç™½ & æ—¶é—´è½´åˆ†é•œ",
                        "ğŸ“¦ JSON å¯¼å‡ºï¼ˆæœ¬æ¬¡ï¼‰",
                        "ğŸ•˜ å†å²è®°å½•ï¼ˆæœ¬ä¼šè¯ï¼‰",
                    ]
                )

                # --- Tab1ï¼šé€å¸§å¡ç‰‡ ---
                with tab_frames:
                    st.markdown(
                        f"å…±æŠ½å– **{len(images)}** ä¸ªå…³é”®å¸§ï¼Œå…¶ä¸­å‰ **{min(len(images), max_ai_frames_safe)}** å¸§åšäº† AI åˆ†æã€‚"
                    )
                    st.markdown("---")

                    for i, (img, info, palette) in enumerate(
                        zip(images, frame_infos, frame_palettes)
                    ):
                        with st.container():
                            st.markdown(f"### ğŸ“˜ å…³é”®å¸§ {i + 1}")

                            c1, c2 = st.columns([1.2, 2])

                            with c1:
                                st.image(
                                    img,
                                    caption=f"ç¬¬ {i + 1} å¸§ç”»é¢",
                                    width=DISPLAY_IMAGE_WIDTH,
                                )
                                palette_img = make_palette_image(palette)
                                st.image(
                                    palette_img,
                                    caption="ä¸»è‰²è°ƒè‰²å¡",
                                    width=PALETTE_WIDTH,
                                )
                                if palette:
                                    hex_list = ", ".join(
                                        rgb_to_hex(c) for c in palette
                                    )
                                    st.caption(f"ä¸»è‰² HEXï¼š{hex_list}")

                            with c2:
                                cam = info.get("camera", {})
                                tags = info.get("tags_zh", [])
                                analysis_lines = [
                                    f"ã€æ™¯åˆ«ã€‘{cam.get('shot_type_zh', '')}",
                                    f"ã€è¿é•œã€‘{cam.get('movement_zh', '')}",
                                    f"ã€æ‹æ‘„è§’åº¦ã€‘{cam.get('angle_zh', '')}",
                                    f"ã€æ„å›¾ã€‘{cam.get('composition_zh', '')}",
                                    f"ã€è‰²å½©ä¸å…‰å½±ã€‘{info.get('color_and_light_zh', '')}",
                                    f"ã€ç”»é¢å†…å®¹ã€‘{info.get('scene_description_zh', '')}",
                                    f"ã€æƒ…ç»ªæ°›å›´ã€‘{info.get('mood_zh', '')}",
                                    f"ã€å…³é”®è¯æ ‡ç­¾ã€‘{' '.join(tags)}",
                                ]
                                analysis_text = "\n".join(analysis_lines).strip()

                                st.markdown("**åˆ†é•œåˆ†æï¼ˆå¯å¤åˆ¶ï¼‰ï¼š**")
                                st.code(
                                    analysis_text
                                    or "ï¼ˆæš‚æ— åˆ†é•œåˆ†æï¼Œå¯èƒ½æœªåš AI åˆ†æï¼‰",
                                    language="markdown",
                                )

                                st.markdown("**äººç‰©åŠ¨ä½œç»†èŠ‚ï¼ˆå¯å¤åˆ¶ï¼‰ï¼š**")
                                st.code(
                                    info.get("character_action_detail_zh")
                                    or "ï¼ˆæš‚æ— åŠ¨ä½œç»†èŠ‚ï¼Œå¯èƒ½æœªåš AI åˆ†æï¼‰",
                                    language="markdown",
                                )

                                st.markdown("**åœºæ™¯ç»†èŠ‚ï¼ˆå¯å¤åˆ¶ï¼‰ï¼š**")
                                scene_detail = info.get("environment_detail_zh", "")
                                props_detail = info.get("props_and_tech_detail_zh", "")
                                scene_text = (scene_detail + "\n\né“å…·ä¸ç§‘æŠ€å…ƒç´ ï¼š" + props_detail).strip()
                                st.code(
                                    scene_text or "ï¼ˆæš‚æ— åœºæ™¯ç»†èŠ‚ï¼Œå¯èƒ½æœªåš AI åˆ†æï¼‰",
                                    language="markdown",
                                )

                                # é«˜çº§ç‰©ç†/ç¯å¢ƒç»†èŠ‚ç»„åˆå±•ç¤º
                                advanced_detail = []
                                if info.get("face_expression_detail_zh"):
                                    advanced_detail.append("ã€é¢éƒ¨ä¸çœ¼ç¥ã€‘" + info["face_expression_detail_zh"])
                                if info.get("cloth_hair_reaction_zh"):
                                    advanced_detail.append("ã€æœè£…ä¸å¤´å‘ã€‘" + info["cloth_hair_reaction_zh"])
                                if info.get("weather_force_detail_zh"):
                                    advanced_detail.append("ã€å¤©æ°”ä¸ç¯å¢ƒåŠ›ã€‘" + info["weather_force_detail_zh"])
                                if info.get("physics_reaction_detail_zh"):
                                    advanced_detail.append("ã€å—åŠ›ä¸ç‰©ç†åé¦ˆã€‘" + info["physics_reaction_detail_zh"])
                                if info.get("structure_damage_detail_zh"):
                                    advanced_detail.append("ã€ç»“æ„æŸåã€‘" + info["structure_damage_detail_zh"])
                                if info.get("debris_motion_detail_zh"):
                                    advanced_detail.append("ã€ç¢ç‰‡é£æ•£ã€‘" + info["debris_motion_detail_zh"])
                                if info.get("fx_detail_zh"):
                                    advanced_detail.append("ã€ç‰¹æ•ˆä¸ç²’å­ã€‘" + info["fx_detail_zh"])
                                if info.get("lighting_color_detail_zh"):
                                    advanced_detail.append("ã€å…‰çº¿ç»†èŠ‚ã€‘" + info["lighting_color_detail_zh"])
                                if info.get("audio_cue_detail_zh"):
                                    advanced_detail.append("ã€å£°éŸ³ä¸èŠ‚å¥ã€‘" + info["audio_cue_detail_zh"])
                                if info.get("edit_rhythm_detail_zh"):
                                    advanced_detail.append("ã€å‰ªè¾‘èŠ‚å¥ã€‘" + info["edit_rhythm_detail_zh"])

                                if advanced_detail:
                                    st.markdown("**é«˜çº§ç‰©ç† / ç¯å¢ƒç»†èŠ‚ï¼ˆå¯å¤åˆ¶ï¼‰ï¼š**")
                                    st.code(
                                        "\n".join(advanced_detail),
                                        language="markdown",
                                    )

                                st.markdown("**SORA / VEO è§†é¢‘æç¤ºè¯ï¼ˆè‹±æ–‡ï¼Œå¯å¤åˆ¶ï¼‰ï¼š**")
                                st.code(
                                    info.get("video_prompt_en") or "ï¼ˆæš‚æ— è§†é¢‘æç¤ºè¯ï¼‰",
                                    language="markdown",
                                )

                                st.markdown("**Midjourney é™å¸§æç¤ºè¯ï¼ˆå¯é€‰ï¼‰ï¼š**")
                                st.code(
                                    info.get("midjourney_prompt")
                                    or "ï¼ˆæš‚æ—  Midjourney æç¤ºè¯ï¼‰",
                                    language="markdown",
                                )

                            st.markdown("---")

                # --- Tab2ï¼šæ•´ä½“åˆ†æ + å¹¿å‘Šæ–‡æ¡ˆ + æ—¶é—´è½´åˆ†é•œ ---
                with tab_story:
                    st.markdown("### ğŸ“š æ•´ä½“å‰§æƒ…ä¸è§†å¬é£æ ¼æ€»ç»“")
                    st.code(overall, language="markdown")

                    st.markdown("### ğŸ¤ 10 ç§’å¹¿å‘Šæ—ç™½è„šæœ¬")
                    st.code(ad_script, language="markdown")

                    st.markdown("### ğŸ¬ æ—¶é—´è½´åˆ†é•œè„šæœ¬ï¼ˆå¯å¤åˆ¶ï¼‰")
                    st.code(timeline_shotlist, language="markdown")

                # --- Tab3ï¼šæœ¬æ¬¡ JSON å¯¼å‡º ---
                with tab_json:
                    st.markdown("### ğŸ“¦ ä¸‹è½½æœ¬æ¬¡åˆ†æçš„ JSON æ–‡ä»¶")
                    st.download_button(
                        label="â¬‡ï¸ ä¸‹è½½æœ¬æ¬¡ video_analysis.json",
                        data=json_str,
                        file_name="video_analysis.json",
                        mime="application/json",
                    )

                    with st.expander("ğŸ” é¢„è§ˆéƒ¨åˆ† JSON å†…å®¹"):
                        preview = json_str[:3000] + (
                            "\n...\n" if len(json_str) > 3000 else ""
                        )
                        st.code(preview, language="json")

                # --- Tab4ï¼šå†å²è®°å½•ï¼ˆå½“å‰ä¼šè¯ï¼‰ ---
                with tab_history:
                    st.markdown("### ğŸ•˜ å½“å‰ä¼šè¯å†å²è®°å½•ï¼ˆåˆ·æ–°é¡µé¢ä¼šæ¸…ç©ºï¼‰")

                    history = st.session_state.get("analysis_history", [])
                    if not history:
                        st.info("å½“å‰ä¼šè¯è¿˜æ²¡æœ‰ä»»ä½•å†å²è®°å½•ã€‚")
                    else:
                        options = [
                            f"{len(history) - i}. {h['created_at']} | {h['meta'].get('source_label','')} | "
                            f"{h['meta'].get('frame_count',0)} å¸§ | åŒºé—´ {h['meta'].get('start_sec_used',0):.1f}-{h['meta'].get('end_sec_used',0):.1f}s"
                            for i, h in enumerate(reversed(history))
                        ]
                        idx_display = st.selectbox(
                            "é€‰æ‹©ä¸€æ¡å†å²è®°å½•æŸ¥çœ‹",
                            options=list(range(len(history))),
                            format_func=lambda i: options[i],
                        )
                        real_index = len(history) - 1 - idx_display
                        selected = history[real_index]

                        st.markdown(
                            f"**IDï¼š** `{selected['id']}`  \n"
                            f"**æ—¶é—´ï¼š** {selected['created_at']}  \n"
                            f"**æ¥æºç±»å‹ï¼š** {selected['meta'].get('source_type','')}  \n"
                            f"**æ¥æºæ ‡è¯†ï¼š** {selected['meta'].get('source_label','')}  \n"
                            f"**åˆ†æåŒºé—´ï¼š** {selected['meta'].get('start_sec_used',0):.1f}â€“{selected['meta'].get('end_sec_used',0):.1f} ç§’  \n"
                            f"**å¸§æ•°ï¼š** {selected['meta'].get('frame_count',0)}  \n"
                            f"**æ¨¡å‹ï¼š** {selected['meta'].get('model','')}"
                        )

                        hist_json = json.dumps(
                            selected["data"], ensure_ascii=False, indent=2
                        )
                        st.download_button(
                            label="â¬‡ï¸ ä¸‹è½½è¯¥å†å²è®°å½• JSON",
                            data=hist_json,
                            file_name=f"video_analysis_{selected['id']}.json",
                            mime="application/json",
                        )

                        frames = selected["data"].get("frames", [])
                        if frames:
                            st.markdown("#### éƒ¨åˆ†å¸§é¢„è§ˆï¼ˆä¸­æ–‡åœºæ™¯ + è‹±æ–‡è§†é¢‘æç¤ºè¯ï¼‰")
                            for f in frames[:3]:
                                st.markdown(f"**ç¬¬ {f.get('index')} å¸§ï¼š**")
                                st.write(f.get("scene_description_zh", ""))
                                vp = f.get("video_prompt_en", "")
                                if vp:
                                    st.code(vp, language="markdown")
                                st.markdown("---")

        except Exception as e:
            st.error(f"ä¸‹è½½æˆ–è§£æè§†é¢‘æ—¶å‘ç”Ÿé”™è¯¯ï¼š{e}")
