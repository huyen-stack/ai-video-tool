import streamlit as st
import google.generativeai as genai
import tempfile
import os
import cv2
import numpy as np
from PIL import Image, ImageDraw
import concurrent.futures
import json

# ========================
# å…¨å±€é…ç½®
# ========================

# å¯æŒ‰éœ€æ›¿æ¢ï¼š
#   "gemini-flash-latest"
#   "gemini-2.5-flash-lite"
#   "gemini-2.5-flash"
GEMINI_MODEL_NAME = "gemini-flash-latest"

# å±•ç¤ºæ—¶çš„å›¾ç‰‡ä¸è‰²å¡å®½åº¦
DISPLAY_IMAGE_WIDTH = 320
PALETTE_WIDTH = 320
PALETTE_HEIGHT = 26

# ========================
# é¡µé¢ / å…¨å±€æ ·å¼
# ========================

st.set_page_config(
    page_title="AI è‡ªåŠ¨å…³é”®å¸§åˆ†é•œåŠ©æ‰‹ Pro",
    page_icon="ğŸ¬",
    layout="wide",
)

# ç®€å•å…¨å±€ CSSï¼Œè®©é¡µé¢æ›´åƒä¸€ä¸ª Landing Page
st.markdown(
    """
    <style>
    /* ä¸»ä½“èƒŒæ™¯ & å­—ä½“å¾®è°ƒ */
    .main {
        background-color: #0f172a;
        color: #e5e7eb;
    }
    /* è®© markdown é‡Œçš„æ–‡å­—é¢œè‰²æ›´æŸ”å’Œ */
    .stMarkdown, .stText {
        color: #e5e7eb;
    }
    /* code åŒºå—å­—ä½“ç¨å°ä¸€ç‚¹ */
    .stCode {
        font-size: 0.85rem !important;
    }
    </style>
    """,
    unsafe_allow_html=True,
)

# é¡¶éƒ¨ Hero åŒºå—
st.markdown(
    """
    <div style="
        padding: 18px 24px;
        border-radius: 18px;
        margin-bottom: 16px;
        background: radial-gradient(circle at top left, #38bdf8 0, #0f172a 45%, #020617 100%);
        border: 1px solid rgba(148, 163, 184, 0.35);
    ">
      <h1 style="margin: 0 0 8px 0; color: #e5e7eb; font-size: 1.6rem;">
        ğŸ¬ AI è‡ªåŠ¨å…³é”®å¸§åˆ†é•œåŠ©æ‰‹ Pro
      </h1>
      <p style="margin: 0; color: #cbd5f5; font-size: 0.96rem;">
        ä¸€é”®è§£ææ•´æ¡è§†é¢‘ï¼Œè‡ªåŠ¨æŠ½å–å…³é”®å¸§ï¼Œç”Ÿæˆ
        <b>åˆ†é•œè„šæœ¬ / ä¸»è‰²è°ƒè‰²å¡ / å‰§æƒ…å¤§çº² / 10 ç§’å¹¿å‘Šæ—ç™½</b>ï¼Œ
        åšå‰ªè¾‘å’Œå¹¿å‘Šç­–åˆ’æ—¶ç›´æ¥å½“ã€ŒAI å¯¼æ¼”åŠ©ç†ã€ç”¨ã€‚
      </p>
    </div>
    """,
    unsafe_allow_html=True,
)

# ========================
# å·¥å…·å‡½æ•°ï¼šæ ¹æ®æ—¶é•¿è‡ªåŠ¨æŠ½å…³é”®å¸§
# ========================

def extract_keyframes_dynamic(
    video_path: str,
    min_frames: int = 6,
    max_frames: int = 30,
    base_fps: float = 1.5,
):
    """
    æ ¹æ®è§†é¢‘æ—¶é•¿è‡ªåŠ¨æŠ½å–å…³é”®å¸§ï¼š
    - æŒ‰æ—¶é•¿ä¼°ç®—ç›®æ ‡å¸§æ•°ï¼šideal_n = duration * base_fps
    - åœ¨ [min_frames, max_frames] èŒƒå›´å†…æˆªå–
    - å‡åŒ€æŠ½å¸§ï¼ˆåç»­å¯å†å åŠ æ›´å¤æ‚çš„â€œé•œå¤´åˆ‡æ¢æ£€æµ‹â€ï¼‰
    è¿”å› PIL.Image åˆ—è¡¨ã€‚
    """
    cap = cv2.VideoCapture(video_path)
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    fps = cap.get(cv2.CAP_PROP_FPS)
    if fps is None or fps <= 1e-2:
        fps = 25.0  # ç»™ä¸ªé»˜è®¤å€¼

    if total_frames <= 0:
        cap.release()
        return []

    duration = total_frames / fps  # ç§’
    ideal_n = int(duration * base_fps)
    target_n = max(min_frames, ideal_n)
    target_n = min(target_n, max_frames, total_frames)

    if target_n <= 0:
        cap.release()
        return []

    # å‡åŒ€æŠ½å¸§ï¼šåœ¨ [0, total_frames) ä¸Šå– target_n ä¸ªç‚¹
    step = total_frames / float(target_n)
    frame_indices = [int(i * step) for i in range(target_n)]

    images = []
    for idx in frame_indices:
        cap.set(cv2.CAP_PROP_POS_FRAMES, idx)
        ret, frame = cap.read()
        if ret and frame is not None:
            rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            images.append(Image.fromarray(rgb_frame))
        else:
            images.append(Image.new("RGB", (200, 200), color="gray"))

    cap.release()
    return images

# ========================
# ä¸»è‰²è°ƒè‰²å¡ç›¸å…³
# ========================

def get_color_palette(pil_img: Image.Image, num_colors: int = 5):
    """
    ä½¿ç”¨ KMeans èšç±»æå–å›¾ç‰‡ä¸»è‰²è°ƒï¼Œè¿”å› [(R,G,B), ...]ã€‚
    """
    img = pil_img.resize((120, 120))
    arr = np.array(img)
    data = arr.reshape((-1, 3)).astype(np.float32)

    criteria = (
        cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER,
        20,
        1.0,
    )
    flags = cv2.KMEANS_RANDOM_CENTERS

    _, labels, centers = cv2.kmeans(
        data,
        num_colors,
        None,
        criteria,
        10,
        flags,
    )
    centers = centers.astype(int)
    colors = [tuple(map(int, c)) for c in centers]
    return colors


def make_palette_image(colors, width: int = PALETTE_WIDTH, height: int = PALETTE_HEIGHT):
    """
    æŠŠä¸€ç»„ RGB é¢œè‰²ç”»æˆä¸€æ¡æ°´å¹³è‰²å¡æ¡ã€‚
    """
    if not colors:
        return Image.new("RGB", (width, height), color="gray")

    bar = Image.new("RGB", (width, height))
    draw = ImageDraw.Draw(bar)
    n = len(colors)
    band_width = max(width // n, 1)

    for i, color in enumerate(colors):
        x0 = i * band_width
        x1 = width if i == n - 1 else (i + 1) * band_width
        draw.rectangle([x0, 0, x1, height], fill=color)

    return bar


def rgb_to_hex(rgb_tuple):
    r, g, b = rgb_tuple
    return "#{:02X}{:02X}{:02X}".format(r, g, b)

# ========================
# è§£æ Gemini è¿”å›
# ========================

def _extract_text_from_response(resp) -> str:
    """
    å…¼å®¹ä¸åŒç‰ˆæœ¬ SDK çš„ Gemini å“åº”è§£æï¼š
    1. ä¼˜å…ˆç”¨ resp.text
    2. å†ä» candidates[].content.parts[].text é‡ŒæŠŠæ–‡æœ¬æ‹¼å‡ºæ¥
    3. å®åœ¨ä¸è¡Œå°±æŠŠ resp è½¬æˆå­—ç¬¦ä¸²è¿”å›
    """
    text = getattr(resp, "text", None)
    if text and isinstance(text, str) and text.strip():
        return text.strip()

    try:
        texts = []
        for cand in getattr(resp, "candidates", []) or []:
            content = getattr(cand, "content", None)
            if not content:
                continue
            for part in getattr(content, "parts", []) or []:
                part_text = getattr(part, "text", None)
                if part_text:
                    texts.append(part_text)
        if texts:
            return " ".join(texts).strip()
    except Exception:
        pass

    try:
        return str(resp)
    except Exception:
        return ""

# ========================
# å•å¸§åˆ†æï¼šè§†å¬è¯­è¨€ + è¯­ä¹‰
# ========================

def analyze_single_image(img: Image.Image, model):
    """
    è°ƒç”¨ Gemini å¯¹å•å¼ å›¾ç‰‡åšä¸“ä¸šçº§åˆ†é•œåˆ†æï¼š
    æ™¯åˆ« / è¿é•œ / è§’åº¦ / æ„å›¾ / è‰²å½©ä¸å…‰å½± / å†…å®¹ / æƒ…ç»ª / æ ‡ç­¾
    """
    try:
        prompt = (
            "ä½ ç°åœ¨æ˜¯ä¸“ä¸šçš„ç”µå½±åˆ†é•œå¸ˆ + æ‘„å½±æŒ‡å¯¼ + çŸ­è§†é¢‘è¿è¥é¡¾é—®ã€‚"
            "è¯·åˆ†æè¿™å¼ ç”»é¢ï¼Œå¹¶ä¸¥æ ¼ä½¿ç”¨ä¸‹é¢çš„ä¸­æ–‡æ¨¡æ¿è¾“å‡ºï¼Œç®€æ´ä½†ä¸“ä¸šï¼š\n\n"
            "ã€æ™¯åˆ«ã€‘ï¼ˆè¿œæ™¯/å…¨æ™¯/ä¸­æ™¯/è¿‘æ™¯/ç‰¹å†™ ç­‰ï¼‰\n"
            "ã€è¿é•œã€‘ï¼ˆæ¨/æ‹‰/æ‘‡/ç§»/è·Ÿ/å‡é™/å›ºå®šé•œå¤´ï¼›å¦‚æ— æ³•åˆ¤æ–­å°±å†™â€œé™æ­¢é•œå¤´â€ï¼‰\n"
            "ã€æ‹æ‘„è§’åº¦ã€‘ï¼ˆä¿¯æ‹/ä»°æ‹/å¹³è§†/ä¸Šå¸è§†è§’ ç­‰ï¼‰\n"
            "ã€æ„å›¾ã€‘ï¼ˆä¾‹å¦‚ï¼šä¸‰åˆ†æ³•/ä¸­å¿ƒæ„å›¾/å¯¹ç§°æ„å›¾/å‰æ™¯-ä¸»ä½“-èƒŒæ™¯ ç­‰ï¼‰\n"
            "ã€è‰²å½©ä¸å…‰å½±ã€‘ï¼ˆç”»é¢è‰²è°ƒï¼šåæš–/åå†·/ä¸­æ€§ï¼›æ˜æš—ï¼šé«˜è°ƒ/ä½è°ƒï¼›å¯ç®€å•æè¿°ä¸»è‰²ï¼‰\n"
            "ã€ç”»é¢å†…å®¹ã€‘ï¼ˆä¸€å¥è¯æè¿°è°åœ¨åšä»€ä¹ˆï¼‰\n"
            "ã€æƒ…ç»ªæ°›å›´ã€‘ï¼ˆä¾‹å¦‚ï¼šè½»æ¾ã€ç”œèœœã€æ²»æ„ˆã€ç´§å¼ ã€å‹æŠ‘ã€é…·ç‚« ç­‰ï¼‰\n"
            "ã€å…³é”®è¯æ ‡ç­¾ã€‘ï¼ˆç”¨ #æ ‡ç­¾ å½¢å¼ç»™å‡º 3-8 ä¸ªï¼Œä¾‹å¦‚ï¼š#å¤œæ™¯ #è‡ªæ‹ #éƒ½å¸‚ #æš–è‰²è°ƒï¼‰\n\n"
            "åªè¾“å‡ºä»¥ä¸Š 8 è¡Œå†…å®¹ï¼Œä¸è¦åŠ è§£é‡Šæˆ–å°æ ‡é¢˜ã€‚"
        )
        resp = model.generate_content([prompt, img])
        text = _extract_text_from_response(resp)
        if not text:
            return "åˆ†æå¤±è´¥ï¼šæ¨¡å‹æœªè¿”å›æ–‡æœ¬å†…å®¹"
        return text
    except Exception as e:
        return f"åˆ†æå¤±è´¥ï¼š{e}"


def analyze_images_concurrently(images, model):
    """
    å¹¶å‘åˆ†æå¤šå¼ å›¾ç‰‡ï¼ŒåŠ é€Ÿæ•´ä½“é€Ÿåº¦ã€‚
    """
    if not images:
        return []

    descriptions = [""] * len(images)
    status = st.empty()
    status.info(f"âš¡ æ­£åœ¨å¹¶å‘åˆ†æ {len(images)} ä¸ªå…³é”®å¸§ï¼Œè¯·ç¨å€™...")

    max_workers = min(len(images), 6)

    with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:
        future_to_index = {
            executor.submit(analyze_single_image, img, model): i
            for i, img in enumerate(images)
        }
        for future in concurrent.futures.as_completed(future_to_index):
            i = future_to_index[future]
            try:
                descriptions[i] = future.result()
            except Exception as e:
                descriptions[i] = f"åˆ†æå¤±è´¥ï¼š{e}"

    status.empty()
    return descriptions

# ========================
# æ•´ä½“è§†é¢‘å±‚é¢çš„æ€»ç»“
# ========================

def analyze_overall_video(frame_descriptions, model):
    """
    åŸºäºè‹¥å¹²å…³é”®å¸§çš„åˆ†æç»“æœï¼Œå¯¹æ•´æ®µè§†é¢‘åšï¼š
    - å‰§æƒ…å¤§çº²
    - æ•´ä½“è§†å¬é£æ ¼
    - è¯é¢˜æ ‡ç­¾
    - å•†ä¸šä¸åˆè§„é£é™©
    """
    n = len(frame_descriptions)
    joined = "\n\n".join(
        f"ç¬¬ {i + 1} å¸§ï¼š\n{desc}" for i, desc in enumerate(frame_descriptions)
    )

    prompt = f"""
ä½ ç°åœ¨æ˜¯èµ„æ·±è§†é¢‘å¯¼æ¼” + å‰ªè¾‘å¸ˆ + çŸ­è§†é¢‘è¿è¥ä¸“å®¶ + å†…å®¹åˆè§„å®¡æ ¸å‘˜ã€‚
ä¸‹é¢æ˜¯ä»ä¸€æ®µè§†é¢‘ä¸­æŠ½å–çš„ {n} ä¸ªå…³é”®å¸§çš„è¯¦ç»†è¯´æ˜ï¼Œè¯·ä½ åŸºäºè¿™äº›è¯´æ˜ï¼Œå¯¹æ•´æ®µè§†é¢‘åšæ•´ä½“åˆ†æã€‚

=== å…³é”®å¸§è¯´æ˜å¼€å§‹ ===
{joined}
=== å…³é”®å¸§è¯´æ˜ç»“æŸ ===

è¯·ä¸¥æ ¼æŒ‰ä¸‹é¢ç»“æ„è¾“å‡ºä¸­æ–‡åˆ†æï¼š

ã€å‰§æƒ…å¤§çº²ã€‘
ç”¨ 2-4 å¥æ¦‚æ‹¬è¿™æ®µè§†é¢‘çš„å¤§è‡´å†…å®¹/äººç‰©å…³ç³»/å‘ç”Ÿåœºæ™¯ã€‚

ã€æ•´ä½“è§†å¬é£æ ¼ã€‘
ä»èŠ‚å¥å¿«æ…¢ã€é•œå¤´æ„Ÿã€è‰²å½©æ°”è´¨ï¼ˆæš–/å†·/æ—¥å¸¸/æ¢¦å¹»ï¼‰ã€æƒ…ç»ªæ°›å›´ç­‰è§’åº¦æ€»ç»“æ•´ä½“é£æ ¼ã€‚

ã€é€‚åˆçš„è¯é¢˜æ ‡ç­¾ã€‘
ç”¨ #æ ‡ç­¾ å½¢å¼ç»™å‡º 5-10 ä¸ªï¼Œé€‚åˆæŠ–éŸ³/å°çº¢ä¹¦/è§†é¢‘å·ç­‰å¹³å°ï¼Œä¾‹å¦‚ï¼š
#åŸå¸‚å¤œæ™¯ #æ²»æ„ˆè‡ªæ‹ #æ°›å›´æ„Ÿç¾å¥³

ã€å•†ä¸šä¸åˆè§„é£é™©ã€‘
ä»â€œè¡€è…¥/æš´åŠ›/è‰²æƒ…/æ”¿æ²»/å“ç‰Œå•†æ ‡â€ç­‰ç»´åº¦ï¼Œç®€å•è¯„ä¼°ï¼š
æ•´ä½“é£é™©çº§åˆ«ï¼šä½ / ä¸­ / é«˜
å¹¶ç”¨ 2-3 å¥è¯è¯´æ˜éœ€è¦æ³¨æ„çš„ç‚¹ï¼ˆä¾‹å¦‚ï¼šæœè£…æš´éœ²ç¨‹åº¦ã€æœªæˆå¹´äººå½¢è±¡ã€æ˜¯å¦æœ‰æ˜æ˜¾å“ç‰Œ Logo ç­‰ï¼‰ã€‚

è¯·ç›´æ¥è¾“å‡ºä»¥ä¸Š 4 ä¸ªå°èŠ‚ï¼Œä¸è¦æ·»åŠ é¢å¤–è¯´æ˜ã€‚
"""
    try:
        resp = model.generate_content(prompt)
        return _extract_text_from_response(resp)
    except Exception as e:
        return f"æ•´ä½“åˆ†æå¤±è´¥ï¼š{e}"

# ========================
# 10 ç§’å¹¿å‘Šæ—ç™½è„šæœ¬ç”Ÿæˆ
# ========================

def generate_ad_script(frame_descriptions, model):
    """
    åŸºäºè‹¥å¹²å…³é”®å¸§çš„åˆ†æï¼Œç”Ÿæˆä¸€æ¡ 10 ç§’å·¦å³çš„ä¸­æ–‡å¹¿å‘Šæ—ç™½è„šæœ¬ã€‚
    """
    n = len(frame_descriptions)
    joined = "\n\n".join(
        f"ç¬¬ {i + 1} å¸§ï¼š\n{desc}" for i, desc in enumerate(frame_descriptions)
    )

    prompt = f"""
ä½ æ˜¯ä¸€åèµ„æ·±å¹¿å‘Šå¯¼æ¼” + æ–‡æ¡ˆã€‚
æˆ‘æœ‰ä¸€ä¸ªç”± {n} ä¸ªç”»é¢ç»„æˆçš„ç«–ç‰ˆçŸ­è§†é¢‘ï¼Œæ—¶é•¿å¤§çº¦ 8-12 ç§’ã€‚
ä¸‹é¢æ˜¯æ¯ä¸ªç”»é¢çš„ä¸“ä¸šåˆ†æï¼Œè¯·ä½ åŸºäºè¿™äº›ä¿¡æ¯ï¼Œå†™ä¸€æ¡é€‚åˆé…åˆè¿™äº›ç”»é¢æ’­æ”¾çš„ä¸­æ–‡å¹¿å‘Šæ—ç™½è„šæœ¬ã€‚

=== å…³é”®å¸§åˆ†æ ===
{joined}
=== å…³é”®å¸§åˆ†æç»“æŸ ===

è¦æ±‚ï¼š
1. æ—ç™½æ€»æ—¶é•¿æ§åˆ¶åœ¨ 8-12 ç§’å·¦å³ï¼ˆæ­£å¸¸è¯­é€Ÿï¼‰ï¼Œæ–‡æœ¬ 35-70 å­—å³å¯ã€‚
2. é£æ ¼ä¸ç”»é¢è°ƒæ€§åŒ¹é…ï¼ˆå¦‚æœæ˜¯æ°›å›´æ„Ÿè‡ªæ‹ï¼Œå°±åæƒ…ç»ª/ç”Ÿæ´»æ–¹å¼ï¼›å¦‚æœæ˜¯äº§å“å±•ç¤ºï¼Œå°±å¤šè®²å–ç‚¹ï¼‰ã€‚
3. ç”¨è‡ªç„¶å£è¯­åŒ–ä¸­æ–‡ï¼Œä¸è¦å‡ºç°â€œç”»é¢ä¸­â€â€œé•œå¤´é‡Œâ€è¿™ç±»å­—çœ¼ï¼Œç›´æ¥å¯¹è§‚ä¼—è¯´è¯ã€‚
4. å¦‚æœç”»é¢çœ‹èµ·æ¥åƒä¸ªäººç”Ÿæ´» vlogï¼Œå¯ä»¥å¼±åŒ–â€œè´­ä¹°å·å¬â€ï¼Œæ›´åå‘æƒ…ç»ªæ„ŸæŸ“ã€‚
5. å¦‚æœç”»é¢ä¸­æœ‰æ˜æ˜¾äº§å“æˆ–å“ç‰Œï¼ˆå¦‚é¥®æ–™ã€é›¶é£Ÿã€æŠ¤è‚¤å“ç­‰ï¼‰ï¼Œå¯ä»¥é€‚å½“åŠ å…¥æ¸©æŸ”çš„â€œç§è‰è¯æœ¯â€ã€‚

è¯·ä¸¥æ ¼æŒ‰ç…§ä¸‹é¢æ ¼å¼è¾“å‡ºï¼š

ã€10ç§’å¹¿å‘Šæ—ç™½è„šæœ¬ã€‘
ï¼ˆåœ¨è¿™é‡Œå†™å®Œæ•´çš„ä¸€æ®µæ—ç™½ï¼Œä¸è¦æ‹†æˆå¤šè¡Œï¼Œä¸è¦æ ‡æ³¨é•œå¤´ç¼–å·ï¼‰

ä¸è¦è¾“å‡ºå…¶ä»–ä»»ä½•å†…å®¹ã€‚
"""
    try:
        resp = model.generate_content(prompt)
        return _extract_text_from_response(resp)
    except Exception as e:
        return f"å¹¿å‘Šæ–‡æ¡ˆç”Ÿæˆå¤±è´¥ï¼š{e}"

# ========================
# ä¾§è¾¹æ ï¼šAPI Key è¾“å…¥
# ========================

with st.sidebar:
    st.header("ğŸ”‘ ç¬¬ä¸€æ­¥ï¼šé…ç½® Gemini API Key")
    api_key = st.text_input(
        "è¾“å…¥ Google API Key",
        type="password",
        help="ç²˜è´´ä½ çš„ Gemini API Keyï¼ˆé€šå¸¸ä»¥ AIza å¼€å¤´ï¼‰",
    )

    st.markdown("---")
    if not api_key:
        st.warning("ğŸ”´ è¿˜æ²¡æœ‰ Keyï¼Œå…ˆå» https://ai.google.dev/ ç”³è¯·ä¸€ä¸ª")
    else:
        st.success("ğŸŸ¢ Key å·²å°±ç»ª")

    st.markdown("### ğŸ“ ä½¿ç”¨æ­¥éª¤")
    st.markdown("1. åœ¨ä¸Šé¢è¾“å…¥ API Key\n2. ä¸Šä¼ è§†é¢‘\n3. ç‚¹å‡»ä¸‹æ–¹æŒ‰é’®ä¸€é”®è§£æ")

# ========================
# åˆå§‹åŒ– Gemini æ¨¡å‹
# ========================

model = None
if api_key:
    try:
        genai.configure(api_key=api_key)
        model = genai.GenerativeModel(GEMINI_MODEL_NAME)
    except Exception as e:
        st.error(f"âŒ åˆå§‹åŒ– Gemini æ¨¡å‹å¤±è´¥ï¼š{e}")
        model = None

# ========================
# ä¸»æµç¨‹ï¼šä¸Šä¼ è§†é¢‘ + æŠ½å¸§ + åˆ†æ + å¸ƒå±€å±•ç¤º
# ========================

uploaded_file = st.file_uploader(
    "ğŸ“‚ ç¬¬äºŒæ­¥ï¼šæ‹–å…¥è§†é¢‘æ–‡ä»¶ï¼ˆå»ºè®® < 50MBï¼‰",
    type=["mp4", "mov", "m4v", "avi", "mpeg"],
)

if uploaded_file and st.button("ğŸš€ ä¸€é”®è§£ææ•´æ¡è§†é¢‘"):
    if not api_key or model is None:
        st.error("è¯·å…ˆåœ¨å·¦ä¾§è¾“å…¥æœ‰æ•ˆçš„ Google API Keyã€‚")
    else:
        # 1. ä¿å­˜ä¸Šä¼ çš„è§†é¢‘åˆ°ä¸´æ—¶æ–‡ä»¶
        suffix = os.path.splitext(uploaded_file.name)[1] or ".mp4"
        with tempfile.NamedTemporaryFile(delete=False, suffix=suffix) as tmp:
            tmp.write(uploaded_file.read())
            tmp_path = tmp.name

        st.info("â³ æ­£åœ¨æ ¹æ®è§†é¢‘æ—¶é•¿è‡ªåŠ¨æŠ½å–å…³é”®å¸§...")
        images = extract_keyframes_dynamic(tmp_path)

        # åˆ é™¤ä¸´æ—¶æ–‡ä»¶
        try:
            os.remove(tmp_path)
        except OSError:
            pass

        if not images:
            st.error("âŒ æ— æ³•ä»è§†é¢‘ä¸­è¯»å–å¸§ï¼Œè¯·æ£€æŸ¥è§†é¢‘æ–‡ä»¶æ˜¯å¦æŸåæˆ–æ ¼å¼å¼‚å¸¸ã€‚")
        else:
            st.success(f"âœ… å·²æˆåŠŸæŠ½å– {len(images)} ä¸ªå…³é”®å¸§ï¼")

            # 2. ä¸»è‰²è°ƒè®¡ç®—
            frame_palettes = []
            for img in images:
                try:
                    palette_colors = get_color_palette(img, num_colors=5)
                except Exception:
                    palette_colors = []
                frame_palettes.append(palette_colors)

            # 3. è°ƒç”¨ Gemini åšé€å¸§åˆ†æ
            with st.spinner("ğŸ§  æ­£åœ¨åˆ†ææ¯ä¸€å¸§çš„æ™¯åˆ«ã€è¿é•œã€æ„å›¾ã€æƒ…ç»ªä¸æ ‡ç­¾..."):
                frame_descriptions = analyze_images_concurrently(images, model)

            # 4. æ•´ä½“æ€»ç»“ & å¹¿å‘Šæ–‡æ¡ˆ
            with st.spinner("ğŸ“š æ­£åœ¨ç”Ÿæˆæ•´æ®µè§†é¢‘çš„å‰§æƒ…å¤§çº²ä¸è¯é¢˜æ ‡ç­¾..."):
                overall = analyze_overall_video(frame_descriptions, model)
            with st.spinner("ğŸ¤ æ­£åœ¨ç”Ÿæˆ 10 ç§’å¹¿å‘Šæ—ç™½è„šæœ¬..."):
                ad_script = generate_ad_script(frame_descriptions, model)

            # 5. Tabs å¸ƒå±€ï¼šåƒç½‘ç«™é‚£æ ·åˆ†åŒºå±•ç¤º
            tab_frames, tab_story, tab_json = st.tabs(
                ["ğŸ å…³é”®å¸§ & é€å¸§åˆ†æ", "ğŸ“š å‰§æƒ…æ€»ç»“ & å¹¿å‘Šæ—ç™½", "ğŸ“¦ JSON å¯¼å‡º"]
            )

            # --- Tab1ï¼šé€å¸§å¡ç‰‡å¸ƒå±€ ---
            with tab_frames:
                st.markdown(
                    f"å…±æŠ½å– **{len(images)}** ä¸ªå…³é”®å¸§ã€‚æ¯ä¸€å¸§ä¸‹æ–¹çš„æ–‡å­—ä¸ºå¯å¤åˆ¶åˆ†é•œåˆ†æã€‚"
                )
                st.markdown("---")

                for i, (img, desc, palette) in enumerate(
                    zip(images, frame_descriptions, frame_palettes)
                ):
                    with st.container():
                        st.markdown(
                            f"#### ğŸ¬ å…³é”®å¸§ {i + 1}",
                        )
                        c1, c2 = st.columns([1.2, 2])

                        with c1:
                            st.image(
                                img,
                                caption=f"ç¬¬ {i + 1} å¸§ç”»é¢",
                                width=DISPLAY_IMAGE_WIDTH,
                            )
                            palette_img = make_palette_image(palette)
                            st.image(
                                palette_img,
                                caption="ä¸»è‰²è°ƒè‰²å¡",
                                width=PALETTE_WIDTH,
                            )
                            if palette:
                                hex_list = ", ".join(rgb_to_hex(c) for c in palette)
                                st.caption(f"ä¸»è‰² HEXï¼š{hex_list}")

                        with c2:
                            st.markdown("**åˆ†é•œåˆ†æï¼ˆå¯å¤åˆ¶ï¼‰ï¼š**")
                            st.code(desc, language="markdown")

                        st.markdown("---")

            # --- Tab2ï¼šæ•´ä½“åˆ†æ + å¹¿å‘Šæ–‡æ¡ˆ ---
            with tab_story:
                st.markdown("### ğŸ“š æ•´ä½“å‰§æƒ…ä¸è§†å¬é£æ ¼æ€»ç»“")
                st.code(overall, language="markdown")

                st.markdown("### ğŸ¤ 10 ç§’å¹¿å‘Šæ—ç™½è„šæœ¬")
                st.code(ad_script, language="markdown")

            # --- Tab3ï¼šJSON å¯¼å‡º ---
            with tab_json:
                st.markdown("### ğŸ“¦ å¯¼å‡º JSON åˆ†æç»“æœ")

                export_frames = []
                for i, (desc, palette) in enumerate(
                    zip(frame_descriptions, frame_palettes)
                ):
                    export_frames.append(
                        {
                            "index": i + 1,
                            "analysis": desc,
                            "palette_rgb": [list(c) for c in (palette or [])],
                            "palette_hex": [rgb_to_hex(c) for c in (palette or [])],
                        }
                    )

                export_data = {
                    "meta": {
                        "model": GEMINI_MODEL_NAME,
                        "frame_count": len(images),
                    },
                    "frames": export_frames,
                    "overall_analysis": overall,
                    "ad_script_10s": ad_script,
                }

                json_str = json.dumps(export_data, ensure_ascii=False, indent=2)

                st.download_button(
                    label="â¬‡ï¸ ä¸‹è½½ JSON åˆ†ææ–‡ä»¶",
                    data=json_str,
                    file_name="video_analysis.json",
                    mime="application/json",
                )

                with st.expander("ğŸ” é¢„è§ˆéƒ¨åˆ† JSON å†…å®¹"):
                    st.code(json_str[:3000] + ("\n...\n" if len(json_str) > 3000 else ""), language="json")
