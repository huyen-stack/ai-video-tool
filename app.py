import streamlit as st
import google.generative_ai as genai
import tempfile
import os
import cv2
from PIL import Image
import concurrent.futures

# --- é¡µé¢é…ç½® ---
st.set_page_config(page_title="AI æé€Ÿåˆ†é•œåŠ©æ‰‹", page_icon="ğŸ¬", layout="wide")

st.title("ğŸ¬ AI è§†é¢‘åˆ†é•œåˆ†æ (å…­æ ¼æé€Ÿç‰ˆ)")
st.markdown("ä¸Šä¼ è§†é¢‘ï¼Œè‡ªåŠ¨æˆªå– 6 å¼ å…³é”®å¸§ï¼Œå¹¶å¹¶å‘è°ƒç”¨ AI è¿›è¡Œè§£è¯´ã€‚")

# --- ä¾§è¾¹æ  ---
with st.sidebar:
    st.header("ğŸ”‘ ç¬¬ä¸€æ­¥")
    api_key = st.text_input("è¾“å…¥ Google API Key", type="password", help="ç²˜è´´ä»¥ AIza å¼€å¤´çš„å¯†é’¥")
    st.markdown("---")
    if not api_key:
        st.warning("ğŸ”´ ç­‰å¾…è¾“å…¥ Key")
    else:
        st.success("ğŸŸ¢ Key å·²å°±ç»ª")
    st.markdown("### ğŸ“ ä½¿ç”¨è¯´æ˜")
    st.markdown("1. ç²˜è´´ Key\n2. ä¸Šä¼ è§†é¢‘\n3. ç‚¹å‡»å¼€å§‹")

# --- æ ¸å¿ƒåŠŸèƒ½ 1: æˆªå–å›¾ç‰‡ ---
def extract_6_keyframes(video_path):
    cap = cv2.VideoCapture(video_path)
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    if total_frames == 0: return []
    
    frame_indices = [int(total_frames * (i + 1) / 7) for i in range(6)]
    images = []
    
    for idx in frame_indices:
        cap.set(cv2.CAP_PROP_POS_FRAMES, idx)
        ret, frame = cap.read()
        if ret:
            rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            images.append(Image.fromarray(rgb_frame))
        else:
            images.append(Image.new('RGB', (200, 200), color='gray'))
    cap.release()
    return images

# --- æ ¸å¿ƒåŠŸèƒ½ 2: å¹¶å‘ AI åˆ†æ ---
def analyze_single_image(img, model):
    try:
        prompt = "è¯·ç”¨ä¸€å¥ä¸­æ–‡ç®€è¿°ç”»é¢å†…å®¹ï¼ˆä¾‹å¦‚äººç‰©åŠ¨ä½œï¼‰å’Œæ™¯åˆ«ï¼ˆç‰¹å†™/å…¨æ™¯ï¼‰ã€‚"
        response = model.generate_content([prompt, img])
        return response.text
    except:
        return "åˆ†æå¤±è´¥"

def analyze_images_concurrently(images, model):
    descriptions = [""] * 6
    status = st.empty()
    status.info("âš¡ï¸ æ­£åœ¨å¯åŠ¨ 6 ä¸ª AI çº¿ç¨‹åŒæ—¶åˆ†æï¼Œè¯·ç¨å€™...")
    
    with concurrent.futures.ThreadPoolExecutor(max_workers=6) as executor:
        future_to_index = {executor.submit(analyze_single_image, img, model): i for i, img in enumerate(images)}
        for future in concurrent.futures.as_completed(future_to_index):
            i = future_to_index[future]
            descriptions[i] = future.result()
            
    status.empty()
    return descriptions

# --- ä¸»ç¨‹åºé€»è¾‘ ---
if api_key:
    try:
        genai.configure(api_key=api_key)
        model = genai.GenerativeModel('gemini-1.5-flash')
    except:
        st.error("Key æ ¼å¼ä¸å¯¹")

    uploaded_file = st.file_uploader("ğŸ“‚ ç¬¬äºŒæ­¥ï¼šæ‹–å…¥è§†é¢‘ (å»ºè®® < 50MB)", type=['mp4', 'mov'])

    if uploaded_file and st.button("ğŸš€ å¼€å§‹æé€Ÿåˆ†æ"):
        tfile = tempfile.NamedTemporaryFile(delete=False, suffix='.mp4')
        tfile.write(uploaded_file.read())
        video_path = tfile.name
        
        with st.spinner('æ­£åœ¨æˆªå–å…³é”®å¸§...'):
            keyframes = extract_6_keyframes(video_path)
            
        if keyframes:
            descriptions = analyze_images_concurrently(keyframes, model)
            st.success("âœ… åˆ†æå®Œæˆï¼")
            st.divider()
            
            cols = st.columns(6)
            for i, col in enumerate(cols):
                with col:
                    st.image(keyframes[i], use_column_width=True, caption=f"é•œå¤´ {i+1}")
                    st.info(descriptions[i])
                    
        os.remove(video_path)

elif not api_key:
    st.info("ğŸ‘ˆ è¯·å…ˆåœ¨å·¦ä¾§è¾“å…¥ Key")
