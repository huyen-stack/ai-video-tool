import streamlit as st
import google.generativeai as genai
import tempfile
import os
import cv2
from PIL import Image
import concurrent.futures


# ========================
# å…¨å±€é…ç½®
# ========================

# ä½ å¯ä»¥åœ¨è¿™é‡Œç»Ÿä¸€åˆ‡æ¢æ¨¡å‹ï¼š
#   - "gemini-flash-latest"
#   - "gemini-2.5-flash-lite"
#   - "gemini-2.5-flash"
GEMINI_MODEL_NAME = "gemini-flash-latest"


# ========================
# å·¥å…·å‡½æ•°
# ========================

def extract_6_keyframes(video_path: str):
    """
    ä»è§†é¢‘ä¸­ç­‰é—´éš”æŠ½å– 6 å¼ å…³é”®å¸§ï¼Œè¿”å› PIL.Image åˆ—è¡¨ã€‚
    """
    cap = cv2.VideoCapture(video_path)
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))

    if total_frames <= 0:
        cap.release()
        return []

    # æŒ‰ 7 ç­‰åˆ†å– 6 ä¸ªä½ç½®ï¼ˆ1/7, 2/7, ... 6/7ï¼‰
    frame_indices = [int(total_frames * (i + 1) / 7) for i in range(6)]
    images = []

    for idx in frame_indices:
        cap.set(cv2.CAP_PROP_POS_FRAMES, idx)
        ret, frame = cap.read()
        if ret and frame is not None:
            rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            images.append(Image.fromarray(rgb_frame))
        else:
            # å ä½ç°å›¾ï¼Œé¿å…åé¢å‡ºé”™
            images.append(Image.new("RGB", (200, 200), color="gray"))

    cap.release()
    return images


def _extract_text_from_response(resp) -> str:
    """
    å…¼å®¹ä¸åŒç‰ˆæœ¬ SDK çš„ Gemini å“åº”è§£æï¼š
    1. ä¼˜å…ˆç”¨ resp.text
    2. å†ä» candidates[].content.parts[].text é‡ŒæŠŠæ–‡æœ¬æ‹¼å‡ºæ¥
    3. å®åœ¨ä¸è¡Œå°±æŠŠ resp è½¬æˆå­—ç¬¦ä¸²è¿”å›ï¼Œæ–¹ä¾¿è°ƒè¯•
    """
    # â‘  å…ˆè¯•è¯• resp.text
    text = getattr(resp, "text", None)
    if text and isinstance(text, str) and text.strip():
        return text.strip()

    # â‘¡ å°è¯•èµ° candidates -> content.parts
    try:
        texts = []
        for cand in getattr(resp, "candidates", []) or []:
            content = getattr(cand, "content", None)
            if not content:
                continue
            for part in getattr(content, "parts", []) or []:
                part_text = getattr(part, "text", None)
                if part_text:
                    texts.append(part_text)
        if texts:
            return " ".join(texts).strip()
    except Exception:
        pass

    # â‘¢ å…œåº•ï¼šç›´æ¥è½¬å­—ç¬¦ä¸²ï¼Œè‡³å°‘èƒ½çœ‹åˆ°æ¨¡å‹è¿”å›çš„å¤§æ¦‚ç»“æ„
    try:
        return str(resp)
    except Exception:
        return ""


def analyze_single_image(img: Image.Image, model):
    """
    è°ƒç”¨ Gemini å¯¹å•å¼ å›¾ç‰‡åšä¸€å¥è¯åˆ†é•œæè¿°ã€‚
    """
    try:
        prompt = (
            "ä½ ç°åœ¨æ˜¯çŸ­è§†é¢‘åˆ†é•œå¸ˆï¼Œè¯·ç”¨ä¸€å¥ç®€çŸ­ä¸­æ–‡æè¿°ç”»é¢ï¼š"
            "åŒ…å«ã€æ™¯åˆ«ï¼šç‰¹å†™/ä¸­æ™¯/å…¨æ™¯ã€‘+ã€ä¸»ä½“æ˜¯è°åœ¨åšä»€ä¹ˆã€‘ã€‚"
        )
        resp = model.generate_content([prompt, img])
        text = _extract_text_from_response(resp)
        if not text:
            return "åˆ†æå¤±è´¥ï¼šæ¨¡å‹æœªè¿”å›æ–‡æœ¬å†…å®¹"
        return text
    except Exception as e:
        return f"åˆ†æå¤±è´¥ï¼š{e}"


def analyze_images_concurrently(images, model):
    """
    å¹¶å‘åˆ†æå¤šå¼ å›¾ç‰‡ï¼ŒåŠ é€Ÿæ•´ä½“é€Ÿåº¦ã€‚
    """
    if not images:
        return []

    descriptions = [""] * len(images)
    status = st.empty()
    status.info("âš¡ æ­£åœ¨å¯åŠ¨å¤šçº¿ç¨‹ AI åˆ†æï¼Œè¯·ç¨å€™...")

    max_workers = min(len(images), 6)

    with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:
        future_to_index = {
            executor.submit(analyze_single_image, img, model): i
            for i, img in enumerate(images)
        }
        for future in concurrent.futures.as_completed(future_to_index):
            i = future_to_index[future]
            try:
                descriptions[i] = future.result()
            except Exception as e:
                descriptions[i] = f"åˆ†æå¤±è´¥ï¼š{e}"

    status.empty()
    return descriptions


# ========================
# Streamlit é¡µé¢é…ç½®
# ========================

st.set_page_config(
    page_title="AI æé€Ÿåˆ†é•œåŠ©æ‰‹",
    page_icon="ğŸ¬",
    layout="wide",
)

st.title("ğŸ¬ AI è§†é¢‘åˆ†é•œåˆ†æï¼ˆå…­æ ¼æé€Ÿç‰ˆï¼‰")
st.markdown(
    "ä¸Šä¼ ä¸€ä¸ªçŸ­è§†é¢‘ï¼Œæˆ‘ä¼šè‡ªåŠ¨ä»ä¸­æˆªå– **6 å¼ å…³é”®å¸§**ï¼Œ"
    "å¹¶ç”¨ Gemini å¹¶å‘ç”Ÿæˆ **ä¸€å¥è¯åˆ†é•œæè¿°**ã€‚"
)


# ========================
# ä¾§è¾¹æ ï¼šAPI Key è¾“å…¥
# ========================

with st.sidebar:
    st.header("ğŸ”‘ ç¬¬ä¸€æ­¥ï¼šé…ç½® API Key")
    api_key = st.text_input(
        "è¾“å…¥ Google API Key",
        type="password",
        help="ç²˜è´´ä½ çš„ Gemini API Keyï¼ˆé€šå¸¸ä»¥ AIza å¼€å¤´ï¼‰",
    )

    st.markdown("---")
    if not api_key:
        st.warning("ğŸ”´ è¿˜æ²¡æœ‰ Keyï¼Œå…ˆå» https://ai.google.dev/ ç”³è¯·ä¸€ä¸ª")
    else:
        st.success("ğŸŸ¢ Key å·²å°±ç»ª")

    st.markdown("### ğŸ“ ä½¿ç”¨æ­¥éª¤")
    st.markdown("1. åœ¨ä¸Šé¢è¾“å…¥ API Key\n2. åœ¨ä¸»ç•Œé¢ä¸Šä¼ è§†é¢‘\n3. ç‚¹å‡»â€œå¼€å§‹æé€Ÿåˆ†æâ€")


# ========================
# åˆå§‹åŒ– Gemini æ¨¡å‹
# ========================

model = None
if api_key:
    try:
        genai.configure(api_key=api_key)
        model = genai.GenerativeModel(GEMINI_MODEL_NAME)
    except Exception as e:
        st.error(f"âŒ åˆå§‹åŒ– Gemini æ¨¡å‹å¤±è´¥ï¼š{e}")
        model = None


# ========================
# ä¸»æµç¨‹ï¼šä¸Šä¼ è§†é¢‘ + æˆªå¸§ + AI åˆ†æ
# ========================

uploaded_file = st.file_uploader(
    "ğŸ“‚ ç¬¬äºŒæ­¥ï¼šæ‹–å…¥è§†é¢‘æ–‡ä»¶ï¼ˆå»ºè®® < 50MBï¼‰",
    type=["mp4", "mov", "m4v", "avi", "mpeg"],
)

if uploaded_file and st.button("ğŸš€ å¼€å§‹æé€Ÿåˆ†æ"):
    if not api_key or model is None:
        st.error("è¯·å…ˆåœ¨å·¦ä¾§è¾“å…¥æœ‰æ•ˆçš„ Google API Keyã€‚")
    else:
        # 1. ä¿å­˜ä¸Šä¼ çš„è§†é¢‘åˆ°ä¸´æ—¶æ–‡ä»¶
        suffix = os.path.splitext(uploaded_file.name)[1] or ".mp4"
        with tempfile.NamedTemporaryFile(delete=False, suffix=suffix) as tmp:
            tmp.write(uploaded_file.read())
            tmp_path = tmp.name

        st.info("â³ æ­£åœ¨ä»è§†é¢‘ä¸­æå– 6 å¼ å…³é”®å¸§...")
        images = extract_6_keyframes(tmp_path)

        # åˆ é™¤ä¸´æ—¶æ–‡ä»¶
        try:
            os.remove(tmp_path)
        except OSError:
            pass

        if not images:
            st.error("âŒ æ— æ³•ä»è§†é¢‘ä¸­è¯»å–å¸§ï¼Œè¯·æ£€æŸ¥è§†é¢‘æ–‡ä»¶æ˜¯å¦æŸåæˆ–æ ¼å¼å¼‚å¸¸ã€‚")
        else:
            st.success("âœ… å·²æˆåŠŸæå– 6 å¼ å…³é”®å¸§ï¼")

            # 2. å±•ç¤ºå…­å®«æ ¼æˆªå›¾
            st.subheader("ğŸ–¼ æˆªå›¾é¢„è§ˆï¼ˆå…­å®«æ ¼ï¼‰")
            cols = st.columns(3)
            for i, img in enumerate(images):
                with cols[i % 3]:
                    st.image(img, caption=f"ç¬¬ {i + 1} å¼ å…³é”®å¸§", use_column_width=True)

            # 3. è°ƒç”¨ Gemini åšåˆ†é•œè§£è¯´
            st.subheader("ğŸ§  AI åˆ†é•œè§£è¯´ç»“æœ")
            with st.spinner("æ­£åœ¨è°ƒç”¨ Gemini è¿›è¡Œå›¾åƒç†è§£ä¸æè¿°..."):
                descriptions = analyze_images_concurrently(images, model)

            # 4. å›¾æ–‡å¯¹åº”è¾“å‡ºï¼Œæ–¹ä¾¿å¤åˆ¶
            for i, desc in enumerate(descriptions):
                st.markdown(f"**ç¬¬ {i + 1} å¼ ï¼š** {desc}")
